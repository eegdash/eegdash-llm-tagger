{
  "few_shot_examples": [
    {
      "dataset_id": "DS004368",
      "pathology": [
        "Schizophrenia/Psychosis"
      ],
      "modality": [
        "Visual"
      ],
      "type": [
        "Perception"
      ],
      "metadata": {
        "title": "Meta-rdk: Preprocessed EEG data",
        "dataset_description": "Name: Meta-rdk: Preprocessed EEG data\nAuthors: Martin Rouy, Matthieu Roger, Dorian Goueytes, Michael Pereira, Paul Roux (and 1 more)\nReferences: \nDOI: doi:10.18112/openneuro.ds004368.v1.0.2",
        "readme": "The study was approved by the ethical committee Sud Méditérannée II (217 R01). Twenty individuals with a schizophrenia spectrum disorder (schizophrenia or schizoaffective disorder, 16 males, 4 females) and 22 healthy participants (15 males, 7 females) from the general population took part in this study. Schizophrenia and schizoaffective disorders were diagnosed based on the Structured Clinical Interview for assessing the DSM-5 criteria. The control group was screened for current or past psychiatric illness, and individuals were excluded if they met the criteria for a severe and persistent mental disorder.\nWe used a visual discrimination task. Stimuli consisted of 100 moving dots within a circle (3° radius) at the center of the screen. On each trial, participants indicated whether the motion direction of the dots was to the left or to the right by reaching and clicking on one of two choice targets (3° radius circle) at the top corners of the screen with a mouse. After 6 seconds without response, a buzz sound rang and a message was displayed inviting the participant to respond quicker. Motion coherence was adapted at the individual level via a 1up/2down staircase procedure in order to match task-performance between groups. Following each perceptual decision, participants were asked to report their confidence about their response using a vertical visual analog scale from 0% (Sure incorrect) to 100% (Sure correct), with 50% confidence meaning “Not sure at all”.",
        "participants_overview": "Gender: [\"F\", \"M\"]; Age: [\"19\", \"23\", \"25\", \"26\", \"27\", \"28\", \"32\", \"34\", \"37\", \"38\" (and 10 more)]; Group: [\"Control\", \"Patient\"]",
        "tasks": [
          "task"
        ],
        "events": [],
        "json_metadata_summary": "=== task-task_events.json ===\nduration: {LongName, Description, Units}\ntrial_type: {LongName, Description}\nresponse_time: {LongName, Description, Units}\nonset: {LongName, Description, Units}\n\n=== sub-S01/ses-1/eeg/sub-S01_ses-1_task-task_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nManufacturer: g.tec\nEEGPlacementScheme: 10-20\nEEGGround: n/a\nEEGReference: AFz\nCapManufacturersModelName: 64 channels\nCapManufacturer: g.tec\nTaskName: task\nEEGChannelCount: 63\nRecordingType: epoched\nEpochLength: 3\nRecordingDuration: 3\nSamplingFrequency: 128\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-S02/ses-1/eeg/sub-S02_ses-1_task-task_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nManufacturer: g.tec\nEEGPlacementScheme: 10-20\nEEGGround: n/a\nEEGReference: AFz\nCapManufacturersModelName: 64 channels\nCapManufacturer: g.tec\nTaskName: task\nEEGChannelCount: 63\nRecordingType: epoched\nEpochLength: 3\nRecordingDuration: 3\nSamplingFrequency: 128\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-S03/ses-1/eeg/sub-S03_ses-1_task-task_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nManufacturer: g.tec\nEEGPlacementScheme: 10-20\nEEGGround: n/a\nEEGReference: AFz\nCapManufacturersModelName: 64 channels\nCapManufacturer: g.tec\nTaskName: task\nEEGChannelCount: 63\nRecordingType: epoched\nEpochLength: 3\nRecordingDuration: 3\nSamplingFrequency: 128\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-S04/ses-1/eeg/sub-S04_ses-1_task-task_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nManufacturer: g.tec\nEEGPlacementScheme: 10-20\nEEGGround: n/a\nEEGReference: AFz\nCapManufacturersModelName: 64 channels\nCapManufacturer: g.tec\nTaskName: task\nEEGChannelCount: 63\nRecordingType: epoched\nEpochLength: 3\nRecordingDuration: 3\nSamplingFrequency: 128\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-S05/ses-1/eeg/sub-S05_ses-1_task-task_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nManufacturer: g.tec\nEEGPlacementScheme: 10-20\nEEGGround: n/a\nEEGReference: AFz\nCapManufacturersModelName: 64 channels\nCapManufacturer: g.tec\nTaskName: task\nEEGChannelCount: 63\nRecordingType: epoched\nEpochLength: 3\nRecordingDuration: 3\nSamplingFrequency: 128\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0",
        "openneuro_name": "Meta-rdk: Preprocessed EEG data",
        "openneuro_doi": "doi:10.18112/openneuro.ds004368.v1.0.2",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 39
      }
    },
    {
      "dataset_id": "DS004574",
      "pathology": [
        "Parkinson's"
      ],
      "modality": [
        "Multisensory"
      ],
      "type": [
        "Clinical/Intervention"
      ],
      "metadata": {
        "title": "Cross-modal Oddball Task.",
        "dataset_description": "Name: Cross-modal Oddball Task.\nAuthors: Arun Singh arun.singh@usd.edu, Rachel Cole rachel-cole@uiowa.edu, Arturo Espinoza arturo-espinoza@uiowa.edu, Jan R Wessel jan-wessel@uiowa.edu, Jim Cavanagh jcavanagh@unm.edu (and 1 more)\nReferences: doi: https://doi.org/10.1101/2022.07.26.22278079\nDOI: doi:10.18112/openneuro.ds004574.v1.0.0",
        "readme": "This experiment includes 146 subjects: 98 individuals with Parkinsons disease, \nand 48 controls. The data were collected from 2017-2021. Subjects completed this oddball task (along with multiple other cognitive tasks) \nwhile EEG was recorded with a 64-channel BrainVision cap. This task includes a primary GO cue,\n(white arrow) that required a directional response. That response could be correct or incorrect. The primary cue \n\nwas preceeded by a visual pre-cue and an auditory pre-cue, which occurred at the same time (500ms before arrow cue). \nEach trial had either standard for both pre-cues, oddball visual pre-cue, or oddball auditory pre-cue. \nOur analysis focused only on trials with both pre-cues standard or oddball auditory pre-cue.",
        "participants_overview": "GROUP: [\"Control\", \"PD\"]; AGE: [\"48\", \"52\", \"53\", \"54\", \"56\", \"57\", \"58\", \"60\", \"61\", \"62\" (and 10 more)]; GENDER: [\"F\", \"M\"]; TYPE: [\"0\", \"1\"]",
        "tasks": [
          "Oddball"
        ],
        "events": [],
        "json_metadata_summary": "=== task-Oddball_events.json ===\nonset: {Description, Units}\nduration: {Description, Units}\n\n=== sub-001/eeg/sub-001_task-Oddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-Oddball_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Oddball\nRecordingType: continuous\nRecordingDuration: 816.2\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/eeg/sub-002_task-Oddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-002/eeg/sub-002_task-Oddball_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Oddball\nRecordingType: continuous\nRecordingDuration: 1087.16\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/eeg/sub-003_task-Oddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-003/eeg/sub-003_task-Oddball_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Oddball\nRecordingType: continuous\nRecordingDuration: 1202.54\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-004/eeg/sub-004_task-Oddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-004/eeg/sub-004_task-Oddball_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Oddball\nRecordingType: continuous\nRecordingDuration: 807.52\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-005/eeg/sub-005_task-Oddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-005/eeg/sub-005_task-Oddball_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Oddball\nRecordingType: continuous\nRecordingDuration: 724.46\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a",
        "openneuro_name": "Cross-modal Oddball Task.",
        "openneuro_doi": "doi:10.18112/openneuro.ds004574.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.1101/2022.07.26.22278079]\nAbstractCognitive dysfunction is a major feature of Parkinson’s disease (PD), but the pathophysiology remains unknown. One potential mechanism is abnormal low-frequency cortical rhythms which engage cognitive functions and are deficient in PD. We tested the hypothesis that midfrontal delta/theta rhythms predict cognitive dysfunction in PD. We recruited 100 PD patients and 49 demographically-similar control participants who completed a series of cognitive control tasks, including the Simon, oddball, and interval timing tasks. We focused on cue-evoked delta (1-4 Hz) and theta (4-7 Hz) rhythms from a single midfrontal EEG electrode (Cz) in PD patients who were either cognitively normal, with mild-cognitive impairments (PDMCI), or had dementia (PDD). We found that PD-related cognitive dysfunction was associated with increased response latencies and decreased midfrontal delta power across all tasks. Within PD patients, the first principal component of evoked EEG features from a single electrode (Cz) strongly correlated with clinical metrics such as the Montreal Cognitive Assessment (MOCA; rho=0.36) and with NIH-toolbox Executive Function scores (rho=0.46). These data demonstrate that cue-evoked midfrontal delta/theta rhythms directly relate to cognition in PD. Our results provide insight into the nature of low-frequency frontal rhythms and suggest that PD-related cognitive dysfunction results from decreased delta/theta activity. These findings could facilitate the development of new biomarkers and targeted therapies for cognitive symptoms of PD.",
        "eegdash_subjects": 146
      }
    },
    {
      "dataset_id": "DS004951",
      "pathology": [
        "Other"
      ],
      "modality": [
        "Tactile"
      ],
      "type": [
        "Learning"
      ],
      "metadata": {
        "title": "Braille letters - EEG",
        "dataset_description": "Name: Braille letters - EEG\nAuthors: Marleen Haupt, Monika Graumann, Santani Teng, Carina Kaltenbach, Radoslaw M. Cichy\nDOI: doi:10.18112/openneuro.ds004951.v1.0.0",
        "readme": "This dataset contains the raw EEG data accompanying the paper \"The transformation of sensory to perceptual braille letter representations in the visually deprived brain\". Please cite the above paper if you use this data.\n\nThe dataset includes:\n\nBrainvision files (.eeg, .vhdr, .vmrk) for all participants.\n\nPlease note, for some participants the EEG decording had to be stopped and restarted within a session. In this case, the different files are indicated as separate runs. In addition, some participants completed a second session.\n\nThe events files contain the onsets, durations, trial types and values for all trials in the corresponding run. Stimuli are Braille letters (B,C,D,L,M,N,V,Z) presented on Braille cells under the left and right index fingers of participants. Triggers S1-8 are letters presented to the left hand, triggers S9-16 are letters presented to the right hand. \n\nOther triggers:\n\nstarttrigger         = S100;\ntrialonset           = S101;\nstimulusonset        = S222;\ncatchtrial           = S200;\npedalpress_correct   = S253;\npedalpress_incorrect = S254;\nendtrigger           = S255;\n\n\nFor a full description of the paradigm and the employed procedures please see the paper.  \n\nReferences for MNE BIDS conversion\n----------\nAppelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., Höchenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A. and Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software 4: (1896). https://doi.org/10.21105/joss.01896\n\nPernet, C. R., Appelhoff, S., Gorgolewski, K. J., Flandin, G., Phillips, C., Delorme, A., Oostenveld, R. (2019). EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Scientific Data, 6, 103. https://doi.org/10.1038/s41597-019-0104-8",
        "participants_overview": "age: [\"29\", \"32\", \"35\", \"39\", \"41\", \"42\", \"48\", \"52\", \"55\", \"61\"]; sex: [\"F\", \"M\"]; group: [\"control\"]",
        "tasks": [],
        "events": [
          "New Segment/",
          "Stimulus/S  1",
          "Stimulus/S  2",
          "Stimulus/S  3",
          "Stimulus/S  4",
          "Stimulus/S  5",
          "Stimulus/S  6",
          "Stimulus/S  7",
          "Stimulus/S  8",
          "Stimulus/S  9",
          "Stimulus/S 10",
          "Stimulus/S 11",
          "Stimulus/S 12",
          "Stimulus/S 13",
          "Stimulus/S 14",
          "Stimulus/S 15",
          "Stimulus/S 16",
          "Stimulus/S100",
          "Stimulus/S101",
          "Stimulus/S200",
          "Stimulus/S222",
          "Stimulus/S253",
          "Stimulus/S254",
          "Stimulus/S255"
        ],
        "json_metadata_summary": "=== sub-02/ses-01/eeg/sub-02_ses-01_space-CapTrak_coordsystem.json ===\nEEGCoordinateSystem: CapTrak\nEEGCoordinateUnits: m\nEEGCoordinateSystemDescription: The X-axis goes from the left preauricular point (LPA) through the right preauricular point (RPA). The Y-axis goes orthogonally to the X-axis through the nasion (NAS). The Z-axis goes orthogonally ...\nAnatomicalLandmarkCoordinateSystem: CapTrak\nAnatomicalLandmarkCoordinateUnits: m\n\n=== sub-02/ses-01/eeg/sub-02_ses-01_task-letters_run-01_eeg.json ===\nTaskName: letters\nManufacturer: Brain Products\nPowerLineFrequency: n/a\nSamplingFrequency: 1000.0\nSoftwareFilters: n/a\nRecordingDuration: 5226.399\nRecordingType: continuous\nEEGReference: n/a\nEEGGround: n/a\nEEGPlacementScheme: based on the extended 10/20 system\nEEGChannelCount: 63\nEOGChannelCount: 1\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\n\n=== sub-07/ses-01/eeg/sub-07_ses-01_space-CapTrak_coordsystem.json ===\nEEGCoordinateSystem: CapTrak\nEEGCoordinateUnits: m\nEEGCoordinateSystemDescription: The X-axis goes from the left preauricular point (LPA) through the right preauricular point (RPA). The Y-axis goes orthogonally to the X-axis through the nasion (NAS). The Z-axis goes orthogonally ...\nAnatomicalLandmarkCoordinateSystem: CapTrak\nAnatomicalLandmarkCoordinateUnits: m\n\n=== sub-07/ses-01/eeg/sub-07_ses-01_task-letters_run-01_eeg.json ===\nTaskName: letters\nManufacturer: Brain Products\nPowerLineFrequency: n/a\nSamplingFrequency: 1000.0\nSoftwareFilters: n/a\nRecordingDuration: 5816.759\nRecordingType: continuous\nEEGReference: n/a\nEEGGround: n/a\nEEGPlacementScheme: based on the extended 10/20 system\nEEGChannelCount: 63\nEOGChannelCount: 1\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\n\n=== sub-10/ses-01/eeg/sub-10_ses-01_space-CapTrak_coordsystem.json ===\nEEGCoordinateSystem: CapTrak\nEEGCoordinateUnits: m\nEEGCoordinateSystemDescription: The X-axis goes from the left preauricular point (LPA) through the right preauricular point (RPA). The Y-axis goes orthogonally to the X-axis through the nasion (NAS). The Z-axis goes orthogonally ...\nAnatomicalLandmarkCoordinateSystem: CapTrak\nAnatomicalLandmarkCoordinateUnits: m\n\n=== sub-10/ses-01/eeg/sub-10_ses-01_task-letters_run-01_eeg.json ===\nTaskName: letters\nManufacturer: Brain Products\nPowerLineFrequency: n/a\nSamplingFrequency: 1000.0\nSoftwareFilters: n/a\nRecordingDuration: 568.199\nRecordingType: continuous\nEEGReference: n/a\nEEGGround: n/a\nEEGPlacementScheme: based on the extended 10/20 system\nEEGChannelCount: 63\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\n\n=== sub-10/ses-01/eeg/sub-10_ses-01_task-letters_run-02_eeg.json ===\nTaskName: letters\nManufacturer: Brain Products\nPowerLineFrequency: n/a\nSamplingFrequency: 1000.0\nSoftwareFilters: n/a\nRecordingDuration: 5021.119\nRecordingType: continuous\nEEGReference: n/a\nEEGGround: n/a\nEEGPlacementScheme: based on the extended 10/20 system\nEEGChannelCount: 63\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\n\n=== sub-10/ses-01/eeg/sub-10_ses-01_task-letters_run-03_eeg.json ===\nTaskName: letters\nManufacturer: Brain Products\nPowerLineFrequency: n/a\nSamplingFrequency: 1000.0\nSoftwareFilters: n/a\nRecordingDuration: 352.739\nRecordingType: continuous\nEEGReference: n/a\nEEGGround: n/a\nEEGPlacementScheme: based on the extended 10/20 system\nEEGChannelCount: 63\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\n\n=== sub-10/ses-02/eeg/sub-10_ses-02_space-CapTrak_coordsystem.json ===\nEEGCoordinateSystem: CapTrak\nEEGCoordinateUnits: m\nEEGCoordinateSystemDescription: The X-axis goes from the left preauricular point (LPA) through the right preauricular point (RPA). The Y-axis goes orthogonally to the X-axis through the nasion (NAS). The Z-axis goes orthogonally ...\nAnatomicalLandmarkCoordinateSystem: CapTrak\nAnatomicalLandmarkCoordinateUnits: m\n\n=...",
        "openneuro_name": "Braille letters - EEG",
        "openneuro_doi": "doi:10.18112/openneuro.ds004951.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 11
      }
    },
    {
      "dataset_id": "DS003522",
      "pathology": [
        "TBI"
      ],
      "modality": [
        "Auditory"
      ],
      "type": [
        "Decision-making"
      ],
      "metadata": {
        "title": "EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI",
        "dataset_description": "Name: EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI\nAuthors: James F Cavanagh, Davin Quinn\nReferences: PMID: 31228481\nDOI: 10.18112/openneuro.ds003522.v1.1.0",
        "readme": "3 stimulus auditory oddball data in control, sub-acute mild TBI, and chronic TBI.   Rest data is also included.   3AOB data published here: 10.1016/j.neuropsychologia.2019.107125.  FYI, same task as this different dataset: https://openneuro.org/datasets/ds003490/versions/1.1.0.   For CTL and sub-acute mTBI: Session 1 was from 3 to 14 days post-injury and was the only session with MRI. (MRI will be uploaded ...later).  Session 2 was ~2 months (1.5 to 3) and Session 3 was ~4 months (3 to 5) following Session 1.   For Chronic TBI, there was only one session for this study.   There was A LOT of subject attrition over timepoints.   Same samples as reported here: https://psycnet.apa.org/record/2020-66677-001   https://pubmed.ncbi.nlm.nih.gov/31344589/   https://pubmed.ncbi.nlm.nih.gov/31368085/  Task included in Matlab programming language.   Data collected 2016-2018 in the Center for Brain Recovery and Repair at the UNM Health Sciences Center.  Check the .xls sheet under code folder for *LOTS* more meta data.   Analysis scripts are included to re-create the paper.  - James F Cavanagh 02/17/2021",
        "participants_overview": "sex: [\"0\", \"1\"]; age: [\"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\" (and 10 more)]; Group: [\"0\", \"1\", \"2\"]",
        "tasks": [],
        "events": [
          "Eyes Closed: Every 1000 ms",
          "Eyes Open: Every 1000 ms",
          "Novel Tone",
          "STATUS",
          "Standard Tone",
          "Target Tone"
        ],
        "json_metadata_summary": "=== sub-001/ses-01/eeg/sub-001_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 965.05\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 1523.3\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 1053.25\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 962.7\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscC...",
        "openneuro_name": "EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI",
        "openneuro_doi": "10.18112/openneuro.ds003522.v1.1.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 96
      }
    },
    {
      "dataset_id": "DS004504",
      "pathology": [
        "Dementia"
      ],
      "modality": [
        "Resting State"
      ],
      "type": [
        "Clinical/Intervention"
      ],
      "metadata": {
        "title": "A dataset of EEG recordings from: Alzheimer's disease, Frontotemporal dementia and Healthy subjects",
        "dataset_description": "Name: A dataset of EEG recordings from: Alzheimer's disease, Frontotemporal dementia and Healthy subjects\nAuthors: Andreas Miltiadous, Katerina D. Tzimourta, Theodora Afrantou, Panagiotis Ioannidis, Nikolaos Grigoriadis (and 6 more)\nAcknowledgment: Please cite:\nData descriptor: 10.3390/data8060095\nFirst study on this dataset: 10.1109/ACCESS.2023.3294618\nReferences: Miltiadous, A., Tzimourta, K. D., Afrantou, T., Ioannidis, P., Grigoriadis, N., Tsalikakis, D. G., Angelidis, P., Tsipouras, M. G., Glavas, E., Giannakeas, N., & Tzallas, A. T. (2023). A Dataset of Scalp EEG Recordings of Alzheimer’s Disease, Frontotemporal Dementia and Healthy Subjects from Routine EEG. Data, 8(6), 95. doi: 10.3390/data8060095; Miltiadous, A., Gionanidis, E., Tzimourta, K. D., Giannakeas, N., & Tzallas, A. T. (2023). DICE-net: A Novel Convolution-Transformer Architecture for Alzheimer Detection in EEG Signals. IEEE Access, 1–1. doi: 10.1109/ACCESS.2023.3294618\nDOI: doi:10.18112/openneuro.ds004504.v1.0.8",
        "readme": "This dataset contains the EEG resting state-closed eyes recordings from 88 subjects in total.\n\nParticipants: 36 of them were diagnosed with Alzheimer's disease (AD group), 23 were diagnosed with Frontotemporal Dementia (FTD group) and 29 were healthy subjects (CN group).\nCognitive and neuropsychological state was evaluated by the international Mini-Mental State Examination (MMSE). MMSE score ranges from 0 to 30, with lower MMSE indicating more severe cognitive decline.\nThe duration of the disease was measured in months and the median value was 25 with IQR range (Q1-Q3) being 24 - 28.5 months.\nConcerning the AD groups, no dementia-related comorbidities have been reported. The average MMSE for the AD group was 17.75 (sd=4.5), for the FTD group was 22.17 (sd=8.22) and for the CN group was 30.\nThe mean age of the AD group was 66.4 (sd=7.9), for the FTD group was 63.6 (sd=8.2), and for the CN group was 67.9 (sd=5.4).\n\nRecordings: Recordings were aquired from the 2nd Department of Neurology of AHEPA General Hospital of Thessaloniki by an experienced team of neurologists. For recording, a Nihon Kohden EEG 2100 clinical device was used,\nwith 19 scalp electrodes (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, and O2) according to the 10-20 international system and 2 reference electrodes (A1 and A2) placed on the mastoids for impendance check, according to the manual of the device. Each recording was performed according to the clinical protocol with participants being in a sitting position having their eyes closed.\nBefore the initialization of each recording, the skin impedance value was ensured to be below 5k?. The sampling rate was 500 Hz with 10uV/mm resolution.\nThe recording montages were anterior-posterior bipolar and referential montage using Cz as the common reference. The referential montage was included in this dataset.\nThe recordings were received under the range of the following parameters of the amplifier: Sensitivity: 10uV/mm, time constant: 0.3s, and high frequency filter at 70 Hz.\nEach recording lasted approximately 13.5 minutes for AD group (min=5.1, max=21.3), 12 minutes for FTD group (min=7.9, max=16.9) and 13.8 for CN group (min=12.5, max=16.5).\nIn total, 485.5 minutes of AD, 276.5 minutes of FTD and 402 minutes of CN recordings were collected and are included in the dataset.\n\nPreprocessing: The EEG recordings were exported in .eeg format and are transformed to BIDS accepted .set format for the inclusion in the dataset.\nAutomatic annotations of the Nihon Kohden EEG device marking artifacts (muscle activity, blinking, swallowing) have not been included for language compatibility purposes\n(If this is an issue, please use the preprocessed dataset in Folder: derivatives).\nThe unprocessed EEG recordings are included in folders named: sub-0XX. Folders named sub-0XX in the subfolder derivatives contain the preprocessed and denoised EEG recordings.\nThe preprocessing pipeline of the EEG signals is as follows. First, a Butterworth band-pass filter 0.5-45 Hz was applied and the signals were re-referenced to A1-A2.\nThen, the Artifact Subspace Reconstruction routine (ASR) which is an EEG artifact correction method included in the EEGLab Matlab software was applied to the signals,\nremoving bad data periods which exceeded the max acceptable 0.5 second window standard deviation of 17, which is considered a conservative window.\nNext, the Independent Component Analysis (ICA) method (RunICA algorithm) was performed, transforming the 19 EEG signals to 19 ICA components.\nICA components that were classified as “eye artifacts” or “jaw artifacts” by the automatic classification routine “ICLabel” in the EEGLAB platform were automatically rejected.\nIt should be noted that, even though the recording was performed in a resting state, eyes-closed condition, eye artifacts of eye movement were still found at some EEG recordings.\n\nA complete analysis of this dataset can be found in the published Data Descriptor paper \"A...",
        "participants_overview": "Gender: [\"F\", \"M\"]; Age: [\"44\", \"49\", \"53\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\" (and 10 more)]; Group: [\"A\", \"C\", \"F\"]",
        "tasks": [],
        "events": [],
        "json_metadata_summary": "=== sub-001/eeg/sub-001_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: A1 A2\nCapManufacturersModelName: EEG 2100\nCapManufacturer: Nihon Kohden\nInstitutionAddress: Arta, Greece\nInstitutionalDepartmentName: Department of Informatics and Telecommunications\nInstitutionName: University of Ioannina\nTaskName: eyesclosed\nEEGChannelCount: 19\nRecordingType: continuous\nRecordingDuration: 599.8\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-002/eeg/sub-002_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: A1 A2\nCapManufacturersModelName: EEG 2100\nCapManufacturer: Nihon Kohden\nInstitutionAddress: Arta, Greece\nInstitutionalDepartmentName: Department of Informatics and Telecommunications\nInstitutionName: University of Ioannina\nTaskName: eyesclosed\nEEGChannelCount: 19\nRecordingType: continuous\nRecordingDuration: 793.1\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-003/eeg/sub-003_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: A1 A2\nCapManufacturersModelName: EEG 2100\nCapManufacturer: Nihon Kohden\nInstitutionAddress: Arta, Greece\nInstitutionalDepartmentName: Department of Informatics and Telecommunications\nInstitutionName: University of Ioannina\nTaskName: eyesclosed\nEEGChannelCount: 19\nRecordingType: continuous\nRecordingDuration: 307.1\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-004/eeg/sub-004_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: A1 A2\nCapManufacturersModelName: EEG 2100\nCapManufacturer: Nihon Kohden\nInstitutionAddress: Arta, Greece\nInstitutionalDepartmentName: Department of Informatics and Telecommunications\nInstitutionName: University of Ioannina\nTaskName: eyesclosed\nEEGChannelCount: 19\nRecordingType: continuous\nRecordingDuration: 707.1\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-005/eeg/sub-005_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: A1 A2\nCapManufacturersModelName: EEG 2100\nCapManufacturer: Nihon Kohden\nInstitutionAddress: Arta, Greece\nInstitutionalDepartmentName: Department of Informatics and Telecommunications\nInstitutionName: University of Ioannina\nTaskName: eyesclosed\nEEGChannelCount: 19\nRecordingType: continuous\nRecordingDuration: 804.1\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0",
        "openneuro_name": "A dataset of EEG recordings from: Alzheimer's disease, Frontotemporal dementia and Healthy subjects",
        "openneuro_doi": "doi:10.18112/openneuro.ds004504.v1.0.8",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 2/2 - DOI: 10.3390/data8060095]\nRecently, there has been a growing research interest in utilizing the electroencephalogram (EEG) as a non-invasive diagnostic tool for neurodegenerative diseases. This article provides a detailed description of a resting-state EEG dataset of individuals with Alzheimer’s disease and frontotemporal dementia, and healthy controls. The dataset was collected using a clinical EEG system with 19 scalp electrodes while participants were in a resting state with their eyes closed. The data collection process included rigorous quality control measures to ensure data accuracy and consistency. The dataset contains recordings of 36 Alzheimer’s patients, 23 frontotemporal dementia patients, and 29 healthy age-matched subjects. For each subject, the Mini-Mental State Examination score is reported. A monopolar montage was used to collect the signals. A raw and preprocessed EEG is included in the standard BIDS format. For the preprocessed signals, established methods such as artifact subspace reconstruction and an independent component analysis have been employed for denoising. The dataset has significant reuse potential since Alzheimer’s EEG Machine Learning studies are increasing in popularity and there is a lack of publicly available EEG datasets. The resting-state EEG data can be used to explore alterations in brain activity and connectivity in these conditions, and to develop new diagnostic and treatment approaches. Additionally, the dataset can be used to compare EEG characteristics between different types of dementia, which could provide insights into the underlying mechanisms of these conditions.",
        "eegdash_subjects": 88
      }
    },
    {
      "dataset_id": "DS005207",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Sleep"
      ],
      "type": [
        "Sleep"
      ],
      "metadata": {
        "title": "Surrey cEEGrid sleep data set",
        "dataset_description": "Name: Surrey cEEGrid sleep data set\nAuthors: Kaare B. Mikkelsen, James K Ebajemito, Maria A Bonmati-Carrion, Nayantara Santhi, Victoria L Revell (and 7 more)\nAcknowledgment: Please cite Mikkelsen et al 2018: https://doi.org/10.1111/jsr.12786\nDOI: doi:10.18112/openneuro.ds005207.v1.0.0",
        "readme": "Surrey sleep data set\n\n**Overview**\n\nThis dataset was collected as part of a research project on wearable sleep monitoring which took place in spring 2017.\n\nThe data set contains nightly EEG recordings from 20 healthy participants ('subjects'). Some recordings are full polysomnography (PSG) measurements, others are cEEGrid measurements. Most subjects have both PSG and ceegrid recordings from the same night, though a few are missing one or the other.\n\n**Format**\n\nThe dataset is formatted according to the Brain Imaging Data Structure. See the 'dataset_description.json' file for the specific BIDS version used. The EEG data format chosen is the '.set' format of EEGLAB.\n\nFor more information, see the following link:\nhttps://bids-specification.readthedocs.io/en/stable/01-introduction.html\n\n\n**Task description**\n\nThe patient performed no tasks. The recording equipment was mounted immediately prior to bedtime, and the recordings took place at the sleep laboratory of the Surrey Clinical Research Centre.\n\nNote that due to a miscommunication during the study, alignment information between cEEGrid and PSG recordings has not been saved. This means that to obtain a useful comparison between the two methods, for instance to align the manual scoring with the cEEGrid recordings, some post processing has to be performed. In the derivative dataset, 'aligned1', we have shared our own best attempt at alignment. \n\nThe data set was previously described in the paper \n'Machine-learning-derived sleep–wake staging from around-the-ear electroencephalogram outperforms manual scoring and actigraphy', Mikkelsen et al 2018, https://doi.org/10.1111/jsr.12786\n\n**Contact**\n\nFor questions regarding this data set, contact: \nKaare Mikkelsen, Mikkelsen.kaare@ece.au.dk, https://orcid.org/0000-0002-7360-8629",
        "tasks": [
          "sleep",
          "sleep",
          "sleep",
          "sleep"
        ],
        "events": [
          "End",
          "Lights Off",
          "Lights On",
          "Marker",
          "Sleep Onset",
          "Start",
          "Unknown"
        ],
        "json_metadata_summary": "=== task-sleep_acq-psg_events.json ===\nonset: {Description}\nduration: {Description}\ntrial_type: {LongName, Levels}\n\n=== sub-001/ses-001/eeg/sub-001_ses-001_task-sleep_acq-PSG_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 128\nEEGReference: A1, A2\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 6\nEOGChannelCount: 3\nECGChannelCount: 1\nEMGChannelCount: 5\nMiscChannelCount: 0\nTriggerChannelCount: 0\nEEGPlacemen...\n\n=== sub-001/ses-001/eeg/sub-001_ses-001_task-sleep_acq-cEEGrid_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 250\nEEGReference: R4b\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 15\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 6\nTriggerChannelCount: 0\nEEGPlacem...\n\n=== sub-003/ses-001/eeg/sub-003_ses-001_task-sleep_acq-PSG_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 128\nEEGReference: A1, A2\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 6\nEOGChannelCount: 3\nECGChannelCount: 1\nEMGChannelCount: 5\nMiscChannelCount: 0\nTriggerChannelCount: 0\nEEGPlacemen...\n\n=== sub-003/ses-001/eeg/sub-003_ses-001_task-sleep_acq-cEEGrid_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 250\nEEGReference: R4b\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 12\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 6\nTriggerChannelCount: 0\nEEGPlacem...\n\n=== sub-004/ses-001/eeg/sub-004_ses-001_task-sleep_acq-PSG_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 128\nEEGReference: A1, A2\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGCha...",
        "openneuro_name": "Surrey cEEGrid sleep data set",
        "openneuro_doi": "doi:10.18112/openneuro.ds005207.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 20
      }
    },
    {
      "dataset_id": "DS004902",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Resting State"
      ],
      "type": [
        "Resting-state"
      ],
      "metadata": {
        "title": "A Resting-state EEG Dataset for Sleep Deprivation",
        "dataset_description": "Name: A Resting-state EEG Dataset for Sleep Deprivation\nAuthors: Chuqin Xiang, Xinrui Fan, Duo Bai, Ke Lv, Xu Lei\nDOI: doi:10.18112/openneuro.ds004902.v1.0.8",
        "readme": "# General information\n                                                                                                                                                                                                                                                      \nThe dataset provides resting-state EEG data (eyes open,partially eyes closed) from 71 participants who underwent two experiments involving normal sleep (NS---session1) and  sleep deprivation(SD---session2) .The dataset also provides information on participants' sleepiness and mood states.\n（Please note here Session 1 (NS) and Session 2 (SD) is not the time order, the time order is counterbalanced across participants and is listed in metadata.）\n\n\n# Dataset \n                                                                                                                                                                                                                                                                 \n## Presentation\n                                                                                                                                                                                                                                                            \nThe data collection was initiated in March 2019 and was terminated in December 2020. The detailed description of the dataset is currently under working by Chuqin Xiang,Xinrui Fan,Duo Bai,Ke Lv and Xu Lei, and will submit to Scientific Data for publication.\n\n  \n                         \n#### EEG acquisition\n                                                                                                                                                                                                                                                       \n* EEG system (Brain Products GmbH, Steing- rabenstr, Germany, 61 electrodes)                                                                                                                                                                                               \n* Sampling frequency: 500Hz\n* Impedances were kept below 5k\n\n     \n## Contact                                                                                                                                                                                                                                                               \n      * If you have any questions or comments, please contact:\n      * Xu Lei: xlei@swu.edu.cn      \n\n## Article\nXiang, C., Fan, X., Bai, D. et al. A resting-state EEG dataset for sleep deprivation. Sci Data 11, 427 (2024). https://doi.org/10.1038/s41597-024-03268-2",
        "participants_overview": "Gender: [\"F\", \"M\"]; Age: [\"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]; SessionOrder: [\"NS->SD\", \"SD->NS\"]; PVT_item1_NS: [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]; PVT_item1_SD: [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]; SSS_NS: [\"1\", \"2\", \"3\", \"4\", \"5\"]; SSS_SD: [\"1\", \"2\", \"3\", \"4\", \"5\", \"7\"]; KSS_NS: [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]; KSS_SD: [\"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]; SleepDiary_item3_NS: [\"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]; PSQI_item1: [\"0\", \"1\", \"2\", \"3\"]; PSQI_item2: [\"0\", \"1\", \"2\", \"3\"]; PSQI_item3: [\"0\", \"1\", \"2\"]; PSQI_item4: [\"0\", \"1\", \"2\", \"3\"]; PSQI_item5: [\"0\", \"1\", \"2\"]; PSQI_item6: [\"0\"]; PSQI_item7: [\"0\", \"1\", \"2\", \"3\"]",
        "tasks": [],
        "events": [],
        "json_metadata_summary": "=== sub-01/ses-1/eeg/sub-01_ses-1_electrodes.json ===\nEEGPlacementScheme: 10-20\nType: EEG\nUnits: millimeters\nCoordinatesDescription: x, y, z refer to position relative to head center\n\n=== sub-01/ses-1/eeg/sub-01_ses-1_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGReference: FCz\nEEGPlacementScheme: 10-20\nCapManufacturer: Brain Products GmbH\nInstitutionAddress: No.2 Tiansheng Road, BeibeiDistrict, Chongqing City, 400715, China\nInstitutionalDepartmentName: Faculty of Psychology\nInstitutionName: Southwest University\nTaskName: eyesclosed\nEEGChannelCount: 61\nRecordingType: continuous\nRecordingDuration: 300\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-01/ses-1/eeg/sub-01_ses-1_task-eyesopen_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGReference: FCz\nInstitutionAddress: No.2 Tiansheng Road, BeibeiDistrict, Chongqing City, 400715, China\nInstitutionalDepartmentName: Faculty of Psychology\nInstitutionName: Southwest University\nEEGPlacementScheme: 10-20\nCapManufacturer: Brain Products GmbH\nTaskName: eyesopen\nEEGChannelCount: 61\nRecordingType: continuous\nRecordingDuration: 300\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-01/ses-2/eeg/sub-01_ses-2_electrodes.json ===\nEEGPlacementScheme: 10-20\nType: EEG\nUnits: millimeters\nCoordinatesDescription: x, y, z refer to position relative to head center\n\n=== sub-01/ses-2/eeg/sub-01_ses-2_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGReference: FCz\nEEGPlacementScheme: 10-20\nCapManufacturer: Brain Products GmbH\nInstitutionAddress: No.2 Tiansheng Road, BeibeiDistrict, Chongqing City, 400715, China\nInstitutionalDepartmentName: Faculty of Psychology\nInstitutionName: Southwest University\nTaskName: eyesclosed\nEEGChannelCount: 61\nRecordingType: continuous\nRecordingDuration: 300\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-01/ses-2/eeg/sub-01_ses-2_task-eyesopen_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGReference: FCz\nInstitutionAddress: No.2 Tiansheng Road, BeibeiDistrict, Chongqing City, 400715, China\nInstitutionalDepartmentName: Faculty of Psychology\nInstitutionName: Southwest University\nEEGPlacementScheme: 10-20\nCapManufacturer: Brain Products GmbH\nTaskName: eyesopen\nEEGChannelCount: 61\nRecordingType: continuous\nRecordingDuration: 300\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-02/ses-1/eeg/sub-02_ses-1_electrodes.json ===\nEEGPlacementScheme: 10-20\nType: EEG\nUnits: millimeters\nCoordinatesDescription: x, y, z refer to position relative to head center\n\n=== sub-02/ses-1/eeg/sub-02_ses-1_task-eyesclosed_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGReference: FCz\nEEGPlacementScheme: 10-20\nCapManufacturer: Brain Products GmbH\nInstitutionAddress: No.2 Tiansheng Road, BeibeiDistrict, Chongqing City, 400715, China\nInstitutionalDepartmentName: Faculty of Psychology\nInstitutionName: Southwest University\nTaskName: eyesclosed\nEEGChannelCount: 61\nRecordingType: continuous\nRecordingDuration: 300\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-02/ses-1/eeg/sub-02_ses-1_task-eyesopen_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGReference: FCz\nInstitutionAddress: No.2 Tiansheng Road, BeibeiDistrict, Chongqing City, 400715, China\nInstitutionalDepartmentName: Faculty of Psychology\nInstitutionName: Southwest University\nEEGPlacementScheme: 10-20\nCapManufacturer: Brain Products GmbH\nTaskName: eyesopen\nEEGChannelCount: 61\nRecordingType: continuous\nRecordingDuration: 300\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-02/ses-2/eeg/sub-02_ses-2_electrodes.json ===\nEEGPlacementScheme: 10-20\nType: EEG\nUnits: millimeters\nCoordinatesDescription: x, y, z refer to p...",
        "openneuro_name": "A Resting-state EEG Dataset for Sleep Deprivation",
        "openneuro_doi": "doi:10.18112/openneuro.ds004902.v1.0.8",
        "openneuro_modalities": [
          "eeg",
          "beh"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 71
      }
    },
    {
      "dataset_id": "DS003838",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Auditory"
      ],
      "type": [
        "Memory"
      ],
      "metadata": {
        "title": "EEG, pupillometry, ECG and photoplethysmography, and behavioral data in the digit span task and rest",
        "dataset_description": "Name: EEG, pupillometry, ECG and photoplethysmography, and behavioral data in the digit span task and rest\nAuthors: Yuri G. Pavlov, Dauren Kasanov, Alexandra I. Kosachenko, Alexander I. Kotyusov\nAcknowledgment: https://doi.org/10.1038/s41597-022-01414-2\nReferences: Pavlov, Y. G., Kasanov, D., Kosachenko, A. I., Kotyusov, A. I., & Busch, N. A. (2022). Pupillometry and electroencephalography in the digit span task. Scientific Data, 9(1), 325. https://doi.org/10.1038/s41597-022-01414-2; Pavlov, Y. G., Gashkova, A. S., Kasanov, D., Kosachenko, A. I., Kotyusov, A. I., & Kotchoubey, B. (2023). Task-evoked pulse wave amplitude tracks cognitive load. Scientific Reports, 13(1), 1–10. https://doi.org/10.1038/s41598-023-48917-5; Kosachenko, A. I., Kasanov, D., Kotyusov, A. I., & Pavlov, Y. G. (2023). EEG and pupillometric signatures of working memory overload. Psychophysiology, n/a(n/a), e14275. https://doi.org/10.1111/psyp.14275\nDOI: doi:10.18112/openneuro.ds003838.v1.0.6",
        "readme": "This dataset consists of raw 64-channel EEG, cardiovascular (electrocardiography and photoplethysmography), and pupillometry data from 86 human participants during 4 minutes of eyes-closed resting and during performance of a classic working memory task – digit span task with serial recall. The participants either memorized (memory) or just listened to (control condition) sequences of 5, 9, or 13 digits presented auditorily with 2 second stimulus onset asynchrony. The dataset can be used for (1) developing algorithms for cognitive load discrimination and detection of cognitive overload; (2) studying neural (event-related potentials and brain oscillations) and peripheral physiological (electrocardiography, photoplethysmography, and pupillometry) signals during encoding and maintenance of each sequentially presented memory item in a fine time scale; (3) correlating cognitive load and individual differences in working memory to neural and peripheral physiology, and studying the relationship between the physiological signals; (4) integration of the physiological findings with the vast knowledge coming from behavioral studies of verbal working memory in simple span paradigms.\n\nEEG, pupillometry, ECG and photoplethysmography, and behavioral data are stored separately in corresponding folders. Each data record can consist of four data folders:\nbeh - behavioral data: correctness of the recall in the memory trials\necg - electrocardiography (ECG) and photoplethysmography (PPG) data\neeg - EEG data\npupil -  pupillometry and eye-tracking data\n\nSome of the participants had some physiological data missing:\nsub-017, sub-094 have no pupillometry data\nsub-017, sub-037, sub-066 have no ECG and PPG data\nsub-013, sub-014, sub-015, sub-016, sub-017, sub-018, sub-019, sub-020, sub-021, sub-022, sub-023, sub-024, sub-025, sub-026, sub-027, sub-028, sub-029, sub-030, sub-031, sub-037, sub-066 have no EEG data",
        "participants_overview": "age: [\"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"36\", \"37\" (and 1 more)]; sex: [\"f\", \"m\"]; hand: [\"b\", \"l\", \"r\"]; eye: [\"l\", \"r\"]; EEG_excluded: [\"no\", \"yes\"]; ECG_excluded: [\"no\", \"yes\"]; pupil_excluded: [\"no\", \"yes\"]; behavior_excluded: [\"no\"]",
        "tasks": [],
        "events": [
          "STATUS",
          "control 01/05: listen to digit 1 (first) in 5 digit sequence",
          "control 01/09: listen to digit 1 (first) in 9 digit sequence",
          "control 01/13: listen to digit 1 (first) in 13 digit sequence",
          "control 02/05: listen to digit 2 in 5 digit sequence",
          "control 02/09: listen to digit 2 in 9 digit sequence",
          "control 02/13: listen to digit 2 in 13 digit sequence",
          "control 03/05: listen to digit 3 in 5 digit sequence",
          "control 03/09: listen to digit 3 in 9 digit sequence",
          "control 03/13: listen to digit 3 in 13 digit sequence",
          "control 04/05: listen to digit 4 in 5 digit sequence",
          "control 04/09: listen to digit 4 in 9 digit sequence",
          "control 04/13: listen to digit 4 in 13 digit sequence",
          "control 05/05: listen to digit 5 (last) in 5 digit sequence",
          "control 05/09: listen to digit 5 in 9 digit sequence",
          "control 05/13: listen to digit 5 in 13 digit sequence",
          "control 06/09: listen to digit 6 in 9 digit sequence",
          "control 06/13: listen to digit 6 in 13 digit sequence",
          "control 07/09: listen to digit 7 in 9 digit sequence",
          "control 07/13: listen to digit 7 in 13 digit sequence",
          "control 08/09: listen to digit 8 in 9 digit sequence",
          "control 08/13: listen to digit 8 in 13 digit sequence",
          "control 09/09: listen to digit 9 (last) in 9 digit sequence",
          "control 09/13: listen to digit 9 in 13 digit sequence",
          "control 10/13: listen to digit 10 in 13 digit sequence",
          "control 11/13: listen to digit 11 in 13 digit sequence",
          "control 12/13: listen to digit 12 in 13 digit sequence",
          "control 13/13: listen to digit 13 (last) in 13 digit sequence",
          "memory 01/05 correct: memorize digit 1 (first) in 5 digit sequence; correctly recalled",
          "memory 01/05 error: memorize digit 1 (first) in 5 digit sequence; forgotten",
          "memory 01/09 correct: memorize digit 1 (first) in 9 digit sequence; correctly recalled",
          "memory 01/09 error: memorize digit 1 (first) in 9 digit sequence; forgotten",
          "memory 01/13 correct: memorize digit 1 (first) in 13 digit sequence; correctly recalled",
          "memory 01/13 error: memorize digit 1 (first) in 13 digit sequence; forgotten",
          "memory 02/05 correct: memorize digit 2 in 5 digit sequence; correctly recalled",
          "memory 02/05 error: memorize digit 2 in 5 digit sequence; forgotten",
          "memory 02/09 correct: memorize digit 2 in 9 digit sequence; correctly recalled",
          "memory 02/09 error: memorize digit 2 in 9 digit sequence; forgotten",
          "memory 02/13 correct: memorize digit 2 in 13 digit sequence; correctly recalled",
          "memory 02/13 error: memorize digit 2 in 13 digit sequence; forgotten"
        ],
        "json_metadata_summary": "=== sub-013/beh/sub-013_task-memory_beh.json ===\ncondition: {Description}\n\n=== sub-013/ecg/sub-013_task-memory_ecg.json ===\nInstitutionName: Ural Federal University\nInstitutionalDepartmentName: Department of Psychology\nPowerLineFrequency: 50\nManufacturersModelName: Brain Products actiCHamp\nEEGGround: n/a\nEEGReference: n/a\nEEGChannelCount: 0\nEOGChannelCount: 0\nECGChannelCount: 1\nMiscChannelCount: 1\nTaskDescription: Sequences of 5, 9, or 13 digits presented auditorily by female voice.The participant were asked to either just listen to the stimuli or memorize them and later recall in correct serial order.\nTaskName: mixed\nRecordingType: continuous\nRecordingDuration: 7355.16\nSamplingFrequency: 1000\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-013/ecg/sub-013_task-memory_events.json ===\nonset: {Description, Units}\n\n=== sub-013/ecg/sub-013_task-rest_ecg.json ===\nInstitutionName: Ural Federal University\nInstitutionalDepartmentName: Department of Psychology\nPowerLineFrequency: 50\nManufacturersModelName: Brain Products actiCHamp\nEEGGround: n/a\nEEGReference: n/a\nEEGChannelCount: 0\nEOGChannelCount: 0\nECGChannelCount: 1\nMiscChannelCount: 1\nTaskDescription: Sequences of 5, 9, or 13 digits presented auditorily by female voice.The participant were asked to either just listen to the stimuli or memorize them and later recall in correct serial order.\nTaskName: mixed\nRecordingType: continuous\nRecordingDuration: 252.741\nSamplingFrequency: 1000\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-013/ecg/sub-013_task-rest_events.json ===\nonset: {Description, Units}\n\n=== sub-013/pupil/sub-013_task-memory_eyetrack.json ===\nTaskName: auditory digit span\nInstitutionName: Ural Federal University\nInstitutionAdress: Yekaterinburg; Russia\nManufacturer: Pupil Labs\nManufacturersModelName: Pupil Core\nSoftwareVersion: n/a\nTaskDescription: digit span task\nInstructions: memory condition: memorize sequence of digits presented by recorded voice and reproduce them verbally when a sign of the microphone appears on the screen; control condition: just linsten to the dig...\nSamplingFrequency: 120\nSampleCoordinateUnit: pixel\nSampleCoordinateSystem: gaze-in-world\nEnvironmentCoordinates: n/a\nEventIdentifier: see _events.json\nRawSamples: 1\nIncludedEyeMovementEvents: None\nDetectionAlgorithm: None\nRecordedEye: BOTH\nScreenSize: n/a\nScreenResolution: 1920 x 1080 px\nAOIDefiniti...\n\n=== sub-014/beh/sub-014_task-memory_beh.json ===\ncondition: {Description}\n\n=== sub-014/ecg/sub-014_task-memory_ecg.json ===\nInstitutionName: Ural Federal University\nInstitutionalDepartmentName: Department of Psychology\nPowerLineFrequency: 50\nManufacturersModelName: Brain Products actiCHamp\nEEGGround: n/a\nEEGReference: n/a\nEEGChannelCount: 0\nEOGChannelCount: 0\nECGChannelCount: 1\nMiscChannelCount: 1\nTaskDescription: Sequences of 5, 9, or 13 digits presented auditorily by female voice.The participant were asked to either just listen to the stimuli or memorize them and later recall in correct serial order.\nTaskName: mixed\nRecordingType: continuous\nRecordingDuration: 7113.32\nSamplingFrequency: 1000\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-014/ecg/sub-014_task-memory_events.json ===\nonset: {Description, Units}\n\n=== sub-014/ecg/sub-014_task-rest_ecg.json ===\nInstitutionName: Ural Federal University\nInstitutionalDepartmentName: Department of Psychology\nPowerLineFrequency: 50\nManufacturersModelName: Brain Products actiCHamp\nEEGGround: n/a\nEEGReference: n/a\nEEGChannelCount: 0\nEOGChannelCount: 0\nECGChannelCount: 1\nMiscChannelCount: 1\nTaskDescription: Sequences of 5, 9, or 13 digits presented auditorily by female voice.The participant were asked to either just listen to the stimuli or memorize them and later recall in correct serial order.\nTaskName: mixed\nRecordingType: continuous\nRecordingDuration: 252.741\nSamplingFrequency: 1000\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-014/ecg/sub-014_task-rest_events.json ===\nonset: {Description, Units}\n\n=== sub-014/pupil/sub-014_task-memory_eyetrack.json =...",
        "openneuro_name": "EEG, pupillometry, ECG and photoplethysmography, and behavioral data in the digit span task and rest",
        "openneuro_doi": "doi:10.18112/openneuro.ds003838.v1.0.6",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/3 - DOI: 10.1038/s41597-022-01414-2]\nAbstract This dataset consists of raw 64-channel EEG, cardiovascular (electrocardiography and photoplethysmography), and pupillometry data from 86 human participants recorded during 4 minutes of eyes-closed resting and during performance of a classic working memory task – digit span task with serial recall. The participants either memorized or just listened to sequences of 5, 9, or 13 digits presented auditorily every 2 seconds. The dataset can be used for (1) developing algorithms for cognitive load discrimination and detection of cognitive overload; (2) studying neural (event-related potentials and brain oscillations) and peripheral (electrocardiography, photoplethysmography, and pupillometry) physiological signals during encoding and maintenance of each sequentially presented memory item; (3) correlating cognitive load and individual differences in working memory to neural and peripheral physiology, and studying the relationship between the physiological signals; (4) integration of the physiological findings with the vast knowledge coming from behavioral studies of verbal working memory in simple span paradigms. The data are shared in Brain Imaging Data Structure (BIDS) format and freely available on OpenNeuro ( https://openneuro.org/datasets/ds003838 ).\n\n---\n\n[Paper 2/3 - DOI: 10.1038/s41598-023-48917-5]\nAbstract Cognitive load is a crucial factor in mentally demanding activities and holds significance across various research fields. This study aimed to investigate the effectiveness of pulse wave amplitude (PWA) as a measure for tracking cognitive load and associated mental effort in comparison to heart rate (HR) during a digit span task. The data from 78 participants were included in the analyses. Participants performed a memory task in which they were asked to memorize sequences of 5, 9, or 13 digits, and a control task where they passively listened to the sequences. PWA and HR were quantified from photoplethysmography (PPG) and electrocardiography (ECG), respectively. Pupil dilation was also assessed as a measure of cognitive load. We found that PWA showed a strong suppression with increasing memory load, indicating sensitivity to cognitive load. In contrast, HR did not show significant changes with task difficulty. Moreover, when memory load exceeded the capacity of working memory, a reversal of the PWA pattern was observed, indicating cognitive overload. In this respect, changes in PWA in response to cognitive load correlated with the dynamics of pupil dilation, suggesting a potential shared underlying mechanism. Additionally, both HR and PWA demonstrated a relationship with behavioral performance, with higher task-evoked HR and lower PWA associated with better memory performance. Our findings suggest that PWA is a more sensitive measure than HR for tracking cognitive load and overload. PWA, measured through PPG, holds significant potential for practical applications in assessing cognitive load due to its ease of use and sensitivity to cognitive overload. The findings contribute to the understanding of psychophysiological indicators of cognitive load and offer insights into the use of PWA as a non-invasive measure in various contexts.\n\n---\n\n[Paper 3/3 - DOI: 10.1111/psyp.14275]\nAbstract Understanding the physiological correlates of cognitive overload has implications for gauging the limits of human cognition, developing novel methods to define cognitive overload, and mitigating the negative outcomes associated with overload. Most previous psychophysiological studies manipulated verbal working memory load in a narrow range (an average load of 5 items). It is unclear, however, how the nervous system responds to a working memory load exceeding typical capacity limits. The objective of the current study was to characterize the central and autonomic nervous system changes associated with memory overload, by means of combined recording of electroencephalogram (EEG) and pupillometry. Eighty‐six participants were presented with a digit span task involving the serial auditory presentation of items. Each trial consisted of sequences of either 5, 9, or 13 digits, each separated by 2 s. Both theta activity and pupil size, after the initial rise, expressed a pattern of a short plateau and a decrease with reaching the state of memory overload, indicating that pupil size and theta possibly have similar neural mechanisms. Based on the described above triphasic pattern of pupil size temporal dynamics, we concluded that cognitive overload causes physiological systems to reset, and release effort. Although memory capacity limits were exceeded and effort was released (as indicated by pupil dilation), alpha continued to decrease with increasing memory load. These results suggest that associating alpha with the focus of attention and distractor suppression is not warranted.",
        "eegdash_subjects": 65
      }
    },
    {
      "dataset_id": "DS004362",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Visual"
      ],
      "type": [
        "Motor"
      ],
      "metadata": {
        "title": "EEG Motor Movement/Imagery Dataset",
        "dataset_description": "Name: EEG Motor Movement/Imagery Dataset\nAuthors: Gerwin Schalk, Dennis J McFarland, Thilo Hinterberger, Niels Birbaumer, Jonathan R Wolpaw\nAcknowledgment: When using this resource, please cite the original publication:\n\nSchalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. BCI2000: A General-Purpose Brain-Computer Interface (BCI)...\nReferences: Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE Transactions on Biomedical Engineering 51(6):1034-1043, 2004.\nDOI: doi:10.18112/openneuro.ds004362.v1.0.0",
        "readme": "##Acknowledgements\nThis data set was originally created and contributed to PhysioBank by Gerwin Schalk (schalk at wadsworth dot org) and his colleagues at the BCI R&D Program, Wadsworth Center, New York State Department of Health, Albany, NY. W.A. Sarnacki collected the data. Aditya Joshi compiled the dataset and prepared the documentation. D.J. McFarland and J.R. Wolpaw were responsible for experimental design and project oversight, respectively. This work was supported by grants from NIH/NIBIB ((EB006356 (GS) and EB00856 (JRW and GS)). \n\n**To access the initial publication of this dataset, please visit this link to PhysioBank: https://physionet.org/content/eegmmidb/1.0.0/**\n\n## Experiment Protocol\n This data set consists of over 1500 one- and two-minute EEG recordings, obtained from 109 volunteers, as described below.                                                                                                                                                                                                  \n                                                                                                                                                                                                                                                                                                                           \nSubjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of the four following tasks:\n                                                                                                                                                                                                                                                                                                                           \n**[Task 1]** A target appears on either the left or the right side of the screen. The subject opens and closes the corresponding fist until the target disappears. Then the subject relaxes.                                                                                                                                         \n**[Task 2]** A target appears on either the left or the right side of the screen. The subject imagines opening and closing the corresponding fist until the target disappears. Then the subject relaxes.                                                                                                                            \n**[Task 3]** A target appears on either the top or the bottom of the screen. The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.                                                                         \n**[Task 4]** A target appears on either the top or the bottom of the screen. The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.                                                               \n                                                                                                                                                                                                                                                                                                                           \nIn summary, the experimental runs were:                                                                                                                                                                                                                                                                                                                                                                               ...",
        "participants_overview": "Gender: [\"F\", \"M\"]; Age: [\"19\", \"20\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"30\" (and 10 more)]; Handedness: [\"L\", \"R\"]",
        "tasks": [
          "motion"
        ],
        "events": [],
        "json_metadata_summary": "=== task-motion_events.json ===\nduration: {LongName, Description, Units}\ntrial_type: {LongName, Description}\nresponse_time: {LongName, Description, Units}\nonset: {LongName, Description, Units}\n\n=== sub-001/eeg/sub-001_task-motion_run-10_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-10_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 125\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-001/eeg/sub-001_task-motion_run-11_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-11_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 125\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-001/eeg/sub-001_task-motion_run-12_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-12_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 125\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-001/eeg/sub-001_task-motion_run-13_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-13_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 125\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-001/eeg/sub-001_task-motion_run-14_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-14_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 125\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-001/eeg/sub-001_task-motion_run-1_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-1_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 61\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\n\n=== sub-001/eeg/sub-001_task-motion_run-2_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-motion_run-2_eeg.json ===\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-10\nEEGReference: Left or right ear lobe\nCapManufacturer: Electro-Cap International, Inc.\nTaskName: motion\nEEGChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 61\nSamplingFrequency: 160\nEOGChannelCount: 0\nECGChannelCount: 0\n...",
        "openneuro_name": "EEG Motor Movement/Imagery Dataset",
        "openneuro_doi": "doi:10.18112/openneuro.ds004362.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 109
      }
    },
    {
      "dataset_id": "DS003458",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Visual"
      ],
      "type": [
        "Affect"
      ],
      "metadata": {
        "title": "EEG: Three armed bandit gambling task",
        "dataset_description": "Name: EEG: Three armed bandit gambling task\nAuthors: James F Cavanagh  jcavanagh@unm.edu\nReferences: PMID: 25676913\nDOI: 10.18112/openneuro.ds003458.v1.1.0",
        "readme": "Healthy control college students.  23 subjects completed the 3-armed bandit task with oscillating probabilities.    For example, the 'blue' stim would slowly move from 20% reinforcing to 90% then back to 20 over many trials.  The other 'red' and 'green' stims would move similarly, but in different phase.  See Fig 1 of the paper.  This makes the task great for investigating reward processing & reward prediction error in the service of novel task set generation.\n\nTask included in Matlab programming language.  \n\nData collected in 2014 in the Cognitive Rhythms and Computation Lab, University of New Mexico.   \n\nI also collected Corrugator EMG (may be labeled EKG) and Skin Conductance on most people.  But quality was dubious so I never did much with it.  Check .xls sheet under code folder.\n\nSome pre-processing scripts are included in code folder as well.   \n\n- James F Cavanagh 01/04/2021",
        "participants_overview": "sex: [\"1\", \"2\"]; age: [\"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\"]",
        "tasks": [],
        "events": [
          "Feedback Loss: \"~\"",
          "Feedback Null: \"No Response\"",
          "Feedback Win: \"+1\"",
          "Fixation",
          "Response: Left",
          "Response: Right",
          "Response: Up",
          "STATUS",
          "Stimulus (Left, Right, Up): X,Y,Z",
          "Stimulus (Left, Right, Up): X,Z,Y",
          "Stimulus (Left, Right, Up): Y,X,Z",
          "Stimulus (Left, Right, Up): Y,Z,X",
          "Stimulus (Left, Right, Up): Z,X,Y",
          "Stimulus (Left, Right, Up): Z,Y,X"
        ],
        "json_metadata_summary": "=== sub-001/eeg/sub-001_task-ThreeArmedBandit_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-001/eeg/sub-001_task-ThreeArmedBandit_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nEOGChannelCount: 1\nECGChannelCount: 1\nEMGChannelCount: 1\nTaskName: ThreeArmedBandit\nMiscChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 1634.75\nSamplingFrequency: 500\nSubjectArtefactDescription: not much to say given this was run 8 years ago...\nSoftwareFilters: n/a\n\n=== sub-001/eeg/sub-001_task-ThreeArmedBandit_events.json ===\nonset: {Description, Units}\n\n=== sub-002/eeg/sub-002_task-ThreeArmedBandit_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/eeg/sub-002_task-ThreeArmedBandit_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nEOGChannelCount: 1\nECGChannelCount: 1\nEMGChannelCount: 1\nTaskName: ThreeArmedBandit\nMiscChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 1634.75\nSamplingFrequency: 500\nSubjectArtefactDescription: not much to say given this was run 8 years ago...\nSoftwareFilters: n/a\n\n=== sub-002/eeg/sub-002_task-ThreeArmedBandit_events.json ===\nonset: {Description, Units}\n\n=== sub-003/eeg/sub-003_task-ThreeArmedBandit_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/eeg/sub-003_task-ThreeArmedBandit_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nEOGChannelCount: 1\nECGChannelCount: 1\nEMGChannelCount: 1\nTaskName: ThreeArmedBandit\nMiscChannelCount: 64\nRecordingType: continuous\nRecordingDuration: 1495.1\nSamplingFrequency: 500\nSubjectArtefactDescription: not much to say given this was run 8 years ago...\nSoftwareFilters: n/a\n\n=== sub-003/eeg/sub-003_task-ThreeArmedBandit_events.json ===\nonset: {Description, Units}\n\n=== sub-004/eeg/sub-004_task-ThreeArmedBandit_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-004/eeg/sub-004_task-ThreeArmedBandit_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nEOGChannelCount: 1\nECGChannelCount: 1\nEMGChannelCount: 1\nTaskName: ThreeArmedBandit\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1691.4\nSamplingFrequency: 500\nSubjectArtefactDescription: not much to say given this was run 8 years ago...\nSoftwareFilters: n/a\n\n=== sub-004/eeg/sub-004_task-ThreeArmedBandit_events.json ===\nonset: {Description, Units}\n\n=== sub-005/eeg/sub-005_task-ThreeArmedBandit_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-005/eeg/sub-005_task-ThreeArmedBandit_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nEOGChannelCount: 1\nECGChannelCount: 1\nEMGChannelCount: 1\nTaskName: ThreeArmedBandit\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1380.55\nSamplingFrequency: 500\nSubjectArtefact...",
        "openneuro_name": "EEG: Three armed bandit gambling task",
        "openneuro_doi": "10.18112/openneuro.ds003458.v1.1.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 23
      }
    },
    {
      "dataset_id": "DS005114",
      "pathology": [
        "TBI"
      ],
      "modality": [
        "Visual"
      ],
      "type": [
        "Attention"
      ],
      "metadata": {
        "title": "EEG: DPX Cog Ctl Task in Acute Mild TBI",
        "dataset_description": "Name: EEG: DPX Cog Ctl Task in Acute Mild TBI\nAuthors: James F Cavanagh\nReferences: DOI: 10.1007/s11682-019-00171-y\nDOI: doi:10.18112/openneuro.ds005114.v1.0.0",
        "readme": "Dot Probe Continuous Performance Task in control & sub-acute mild TBI.   Published here: https://pubmed.ncbi.nlm.nih.gov/31368085/    For CTL and sub-acute mTBI: Session 1 was from 3 to 14 days post-injury and was the only session with MRI. MRI will be uploaded later (bug issues on upload).  Session 2 was ~2 months (1.5 to 3) and Session 3 was ~4 months (3 to 5) following Session 1.   There was A LOT of subject attrition over timepoints.   Same samples as reported here: https://psycnet.apa.org/record/2020-66677-001   https://pubmed.ncbi.nlm.nih.gov/31344589/  10.1016/j.neuropsychologia.2019.107125   Task included in Matlab programming language.   Data collected 2016-2018 in the Center for Brain Recovery and Repair at the UNM Health Sciences Center.  Check the .xls sheet under code folder for *LOTS* more meta data.   Analysis scripts are included.  - James F Cavanagh 04/29/2024",
        "participants_overview": "sex: [\"0\", \"1\"]; age: [\"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\" (and 10 more)]; Group: [\"0\", \"1\"]",
        "tasks": [],
        "events": [
          "CueAOnset",
          "CueBOnset",
          "Feedback: CueErr",
          "Feedback: CueNoResp",
          "Feedback: ProbeErr",
          "Feedback: ProbeNoResp",
          "Practice: filler trigger",
          "Probe_aX_onset",
          "Probe_aY_onset",
          "Probe_bY_onset",
          "Response: CueCorr",
          "Response: CueIncorr",
          "Response: Probe_Corr",
          "Response: Probe_Incorr",
          "STATUS"
        ],
        "json_metadata_summary": "=== sub-001/ses-01/eeg/sub-001_ses-01_task-DPX_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-DPX_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: DPX\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 2196.55\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-DPX_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-DPX_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-DPX_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: DPX\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 2204.75\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-DPX_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-DPX_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-DPX_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: DPX\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 1947.95\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-DPX_events.json ===\nonset: {Description, Units}\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-DPX_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-DPX_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: DPX\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 1922.15\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-DPX_events.json ===\nonset: {Description, Units}\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-DPX_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-DPX_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: DPX\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 2277.95\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-DPX_events.json ===\nonset: {Description, Units}\n\n=== sub-004/ses-02/eeg/sub-004_ses-02_task-DPX_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateS...",
        "openneuro_name": "EEG: DPX Cog Ctl Task in Acute Mild TBI",
        "openneuro_doi": "doi:10.18112/openneuro.ds005114.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.1007/s11682-019-00171-y]\nSome of the most disabling aspects of mild traumatic brain injury (mTBI) include lingering deficits in executive functioning. It is known that mTBI can damage white matter tracts, but it remains unknown how this structural brain damage translates into cognitive deficits. This experiment utilized theta band phase synchrony to identify the dysfunctional neural operations that contribute to cognitive problems following mTBI. Sub-acute stage (&lt; 2&#xa0;weeks) mTBI patients (N&#x2009;=&#x2009;52) and healthy matched controls (N&#x2009;=&#x2009;32) completed a control-demanding task with concurrent EEG. Structural MRI was also collected. While there were no performance-specific behavioral differences between groups in the dot probe expectancy task, the degree of theta band phase synchrony immediately following injury predicted the degree of symptom recovery two months later. Although there were no differences in fractional anisotropy (FA) between groups, joint independent components analysis revealed that a smaller network of lower FA-valued voxels contributed to a diminished frontal theta phase synchrony network in the mTBI group. This finding suggests that frontal theta band markers of cognitive control are sensitive to sub-threshold structural aberrations following mTBI.",
        "eegdash_subjects": 91
      }
    },
    {
      "dataset_id": "DS003753",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Visual"
      ],
      "type": [
        "Learning"
      ],
      "metadata": {
        "title": "EEG: Probabilistic Learning with Affective Feedback: Exp #2",
        "dataset_description": "Name: EEG: Probabilistic Learning with Affective Feedback: Exp #2\nAuthors: Darin R. Brown, Trevor Jackson, James F Cavanagh\nReferences: pending\nDOI: 10.18112/openneuro.ds003753.v1.1.0",
        "readme": "RL task in N=25 college age participants.  Data collected circa 2019 in the CRCL at UNM.  The paper [Brown, D.R., Jackson, T.J. & Cavanagh, J.F.  The Reward Positivity is sensitive to affective liking]  Should be coming out in Cognitive, Affective, & Behavioral Neuroscience.  THIS IS EXPERIMENT #2.  Your best bet for understanding this task  would be to read that paper first.   Note we have since made minor adjustments to the task which really enhance the ability to resolve the RewP.  I also have  analytic scripts for it.  If you are interetsted in running this task, contact me for the new version. - James F Cavanagh 07/02/2021",
        "participants_overview": "sex: [\"F\", \"M\"]; age: [\"18\", \"19\", \"20\", \"22\", \"27\"]",
        "tasks": [],
        "events": [
          "CUE: A - EASY PUPPY",
          "CUE: B - HARD PUPPY",
          "CUE: C - EASY COW",
          "CUE: D - HARD COW",
          "FB: LOSE COW",
          "FB: LOSE PUPPY",
          "FB: WIN COW",
          "FB: WIN PUPPY",
          "Left Button",
          "Right Button",
          "STATUS"
        ],
        "json_metadata_summary": "=== sub-001/eeg/sub-001_task-ProbabilisticSelection_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-001/eeg/sub-001_task-ProbabilisticSelection_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ProbabilisticSelection\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1568.5\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-001/eeg/sub-001_task-ProbabilisticSelection_events.json ===\nonset: {Description, Units}\n\n=== sub-002/eeg/sub-002_task-ProbabilisticSelection_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/eeg/sub-002_task-ProbabilisticSelection_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ProbabilisticSelection\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1504.05\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/eeg/sub-002_task-ProbabilisticSelection_events.json ===\nonset: {Description, Units}\n\n=== sub-003/eeg/sub-003_task-ProbabilisticSelection_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/eeg/sub-003_task-ProbabilisticSelection_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ProbabilisticSelection\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1348.75\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/eeg/sub-003_task-ProbabilisticSelection_events.json ===\nonset: {Description, Units}\n\n=== sub-004/eeg/sub-004_task-ProbabilisticSelection_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-004/eeg/sub-004_task-ProbabilisticSelection_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ProbabilisticSelection\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1443.25\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-004/eeg/sub-004_task-ProbabilisticSelection_events.json ===\nonset: {Description, Units}\n\n=== sub-005/eeg/sub-005_task-ProbabilisticSelection_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-005/eeg/sub-005_task-ProbabilisticSelection_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ProbabilisticSelection\nMiscChannelCount: 66\nRecordingType: continuous\nRecordingDuration: 1543.35\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-005/eeg/sub-005_task-ProbabilisticSelection_events.json ===\nonset: {Description, Units}",
        "openneuro_name": "EEG: Probabilistic Learning with Affective Feedback: Exp #2",
        "openneuro_doi": "10.18112/openneuro.ds003753.v1.1.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 25
      }
    },
    {
      "dataset_id": "DS003506",
      "pathology": [
        "Parkinson's"
      ],
      "modality": [
        "Visual"
      ],
      "type": [
        "Decision-making"
      ],
      "metadata": {
        "title": "EEG: Reinforcement Learning in Parkinson's",
        "dataset_description": "Name: EEG: Reinforcement Learning in Parkinson's\nAuthors: James F Cavanagh, Darin Brown\nReferences: PMID: 31704082\nDOI: 10.18112/openneuro.ds003506.v1.1.0",
        "readme": "Reinforcement learning task with 28 Parkinson patients and 28 matched controls.  Task with volitional and instucted choices.   Task adapted from here: https://doi.org/10.1016/j.neuron.2014.06.035.    Beh data first published here: 10.1016/j.cortex.2017.02.021.  EEG published here: 10.1016/j.brainres.2019.146541.   PD came in twice separated by a week, either ON or OFF medication.  CTL only came in once.  Task included in Matlab programming language.   Data collected circa 2015 in Cognitive Rhythms and Computation Lab at University of New Mexico.  Subjs also had an acceleromter taped to their most tremor affected hand.  X, Y, Z dimensions recorded throughout.  Check the .xls sheet under code folder for more meta data.  Some Matlab analytic scripts are included, but I didnt ensure that these are complete.  Also behavioral files from the task, which contain more trial-specific information than the triggers.  \n - James F Cavanagh 02/05/2021",
        "participants_overview": "Group: [\"CTL\", \"PD\"]; sess1_Med: [\"OFF\", \"ON\"]; sess2_Med: [\"OFF\", \"ON\", \"no s2\"]; sex: [\"Female\", \"Male\"]; age: [\"48\", \"49\", \"52\", \"55\", \"58\", \"60\", \"61\", \"64\", \"65\", \"66\" (and 10 more)]",
        "tasks": [],
        "events": [
          "FB: \"No Match\"",
          "FB: \"Too Slow\"",
          "FB: +1",
          "FB: 0",
          "Imperative Stimulus",
          "Instr: \"Choose\"",
          "Instr: \"Match\"",
          "Left Button Choice",
          "Right Button Choice",
          "STATUS"
        ],
        "json_metadata_summary": "=== sub-001/ses-01/eeg/sub-001_ses-01_task-ReinforcementLearning_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-ReinforcementLearning_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ReinforcementLearning\nMiscChannelCount: 67\nRecordingType: continuous\nRecordingDuration: 1409.8\nSamplingFrequency: 500\nSubjectArtefactDescription: CTL\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-ReinforcementLearning_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ReinforcementLearning_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ReinforcementLearning_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ReinforcementLearning\nMiscChannelCount: 67\nRecordingType: continuous\nRecordingDuration: 1920.25\nSamplingFrequency: 500\nSubjectArtefactDescription: PD\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ReinforcementLearning_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ReinforcementLearning_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ReinforcementLearning_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ReinforcementLearning\nMiscChannelCount: 67\nRecordingType: continuous\nRecordingDuration: 624.25\nSamplingFrequency: 500\nSubjectArtefactDescription: PD\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ReinforcementLearning_events.json ===\nonset: {Description, Units}\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ReinforcementLearning_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ReinforcementLearning_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ReinforcementLearning\nMiscChannelCount: 67\nRecordingType: continuous\nRecordingDuration: 1522.85\nSamplingFrequency: 500\nSubjectArtefactDescription: PD\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ReinforcementLearning_events.json ===\nonset: {Description, Units}\n\n=== sub-003/ses-02/eeg/sub-003_ses-02_task-ReinforcementLearning_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/ses-02/eeg/sub-003_ses-02_task-ReinforcementLearning_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Psychology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ReinforcementLearning\nMiscChannelCount: 67\nRecordingType: continuous\nRecordingDuration:...",
        "openneuro_name": "EEG: Reinforcement Learning in Parkinson's",
        "openneuro_doi": "10.18112/openneuro.ds003506.v1.1.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 56
      }
    },
    {
      "dataset_id": "DS004356",
      "pathology": [
        "Healthy"
      ],
      "modality": [
        "Auditory"
      ],
      "type": [
        "Perception"
      ],
      "metadata": {
        "title": "Subcortical responses to music and speech are alike while cortical responses diverge",
        "dataset_description": "Name: Subcortical responses to music and speech are alike while cortical responses diverge\nAuthors: Tong Shan, Madeline S. Cappelloni, Ross K. Maddox\nReferences: Shan, T., Cappelloni, M.S. & Maddox, R.K. Subcortical responses to music and speech are alike while cortical responses diverge. Sci Rep 14, 789 (2024). https://doi.org/10.1038/s41598-023-50438-0\nDOI: doi:10.18112/openneuro.ds004356.v2.2.1",
        "readme": "# README\n\n## Details related to access to the data\n\nPlease contact the following authors for further information:\n- Tong Shan (email: tshan@ur.rochester.edu)\n- Ross K. Maddox (email: rmaddox@ur.rochester.edu)\n\n## Overview\n\nThe goal of this study is to derive Auditory Brainstem Response (ABR) from continuous music and speech stimuli using deconvolution method. Data collected from Jun to Aug, 2021.\n\nThe details of the experiment can be found at Shan et al. (2024). There were two phases in this experiment. For the first phase, ten trials of one-minute clicks were presented to the subjects. For the second phase, the 12 types (six genres of music and six types of speech) of 12 s stimuli clips were presented. There were 40 trials \nfor each type with shuffled order. Between trials, there was a 0.5 s pause. \n\nThe code for stimulus preprocessing and EEG analysis is available on Github: \n\nhttps://github.com/maddoxlab/Music_vs_Speech_abr\n\n\n## Format\n\nThis dataset is formatted according to the EEG Brain Imaging Data Structure. It includes EEG recording from subject 001 to subject 024 (excluding subject 014 and subject 021) in raw brainvision format (including `.eeg`, `.vhdr`, and `.vmrk` triplet) and stimuli files in format of `.wav`. \n\nFor some subjects (sub-03 & sub-19), there are 2 \"runs\" of data that the first run (`run-01`) only contains the click phase (phase 1), and the second run includes the data for the ABR analysis. \n\nTriggers with values of \"1\" were recorded to the onset of the stimulus, and shortly after triggers with values of \"4\" or \"8\" were stamped to indicate the stimulus types and the trial number out of 40. This was done by converting the decimal trial number to bits, denoted b, then calculating 2 ** (b + 2). Triggers of \"999\" denote the start of a new segment of EEG. We've specified these trial numbers and more metadata of the events in each of the `*_eeg_events.tsv` file, which is sufficient to know which trial corresponded to which type of stimulus and which file.\n\n\n## Subjects\n\n24 subjects participated in this study.\n\n**Subject inclusion criteria**\n1. Age between 18-40.\n2. Normal hearing: audiometric thresholds of 20 dB HL or better from 500 to 8000 Hz.\n3. Speak English as their primary language.\n4. Self-reported normal or correctable to normal vision.\n\n**Subject exclusion criteria**\n1. Subject 014 self-withdrew partway through the experiment.\n2. Subject 021 was excluded because of technical problems during data collection that led to unusable data.\n\nTherefore, after excluding the two subjects, there were 22 subjects (11 male and 11 female) with an age of 22.7 ± 5.1 (mean ± SD) years that we included in the analysis. Please see `subjects.tsv` for more demography.\n\n## Apparatus\n\nSubjects were seated in a sound-isolating booth on a chair in front of a 24-inch BenQ monitor with a viewing distance of approximately 60 cm. Stimuli were presented at an average level of 65 dB SPL and a sampling rate of 48000 Hz through ER-2 insert earphones plugged into an RME Babyface Pro digital sound card. The stimulus presentation for the experiment was controlled by a python script using a custom package, `expyfun`.",
        "participants_overview": "gender: [\"Female\", \"Male\"]; age: [\"19\", \"20\", \"22\", \"23\", \"25\", \"28\", \"30\", \"35\", \"37\"]; tonal_language_speaker: [\"No\", \"Yes\"]; L_500: [\"0\", \"10\", \"15\", \"5\"]; L_1000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; L_2000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; L_3000: [\"-5\", \"0\", \"10\", \"5\"]; L_4000: [\"0\", \"10\", \"20\", \"5\"]; L_6000: [\"0\", \"10\", \"15\", \"5\"]; L_8000: [\"0\", \"10\", \"15\", \"5\"]; R_500: [\"0\", \"10\", \"5\"]; R_1000: [\"0\", \"10\", \"15\", \"5\"]; R_2000: [\"-5\", \"0\", \"10\", \"5\"]; R_3000: [\"-5\", \"0\", \"5\"]; R_4000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; R_6000: [\"0\", \"10\", \"20\", \"5\"]; R_8000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; note: [\"EEG 2 runs\"]",
        "tasks": [
          "MusicvsSpeech",
          "MusicvsSpeech"
        ],
        "events": [
          "acoustic",
          "chn_aud",
          "classical",
          "click",
          "eng_aud",
          "hiphop",
          "interview",
          "jazz",
          "lecture",
          "metal",
          "news",
          "pop",
          "talk"
        ],
        "task_details": "Task 'MusicvsSpeech':\nTaskName: MusicvsSpeech\nTaskDescription: For the first phase, subjects listened to 10 trials (each 60 seconds long) clicks. For the second phase, subjects listened to 40 trials (each 12 seconds long) each of six genres of music and six types of speech (480 trials in total), while seated in a sound-isolating booth on a chair in front of a monitor. Subjects were encouraged to rest or sleep and did not have to pay attention to the audio. Subjects were asked to stay awake and paying attention to the sounds.",
        "json_metadata_summary": "=== task-MusicvsSpeech_events.json ===\nonset: {Description, Units}\nduration: {Description, Units}\ntrial_type: {Description, Levels}",
        "openneuro_name": "Subcortical responses to music and speech are alike while cortical responses diverge",
        "openneuro_doi": "doi:10.18112/openneuro.ds004356.v2.2.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.1038/s41598-023-50438-0]\nAbstractMusic and speech are encountered daily and are unique to human beings. Both are transformed by the auditory pathway from an initial acoustical encoding to higher level cognition. Studies of cortex have revealed distinct brain responses to music and speech, but differences may emerge in the cortex or may be inherited from different subcortical encoding. In the first part of this study, we derived the human auditory brainstem response (ABR), a measure of subcortical encoding, to recorded music and speech using two analysis methods. The first method, described previously and acoustically based, yielded very different ABRs between the two sound classes. The second method, however, developed here and based on a physiological model of the auditory periphery, gave highly correlated responses to music and speech. We determined the superiority of the second method through several metrics, suggesting there is no appreciable impact of stimulus class (i.e., music vs speech) on the way stimulus acoustics are encoded subcortically. In this study’s second part, we considered the cortex. Our new analysis method resulted in cortical music and speech responses becoming more similar but with remaining differences. The subcortical and cortical results taken together suggest that there is evidence for stimulus-class dependent processing of music and speech at the cortical but not subcortical level.",
        "eegdash_subjects": 22
      }
    },
    {
      "dataset_id": "DS003555",
      "pathology": [
        "Epilepsy"
      ],
      "modality": [
        "Resting State"
      ],
      "type": [
        "Clinical/Intervention"
      ],
      "metadata": {
        "title": "Dataset of EEG recordings of pediatric patients with epilepsy based on the 10-20 system ",
        "dataset_description": "Name: Dataset of EEG recordings of pediatric patients with epilepsy based on the 10-20 system \nAuthors: Dorottya Cserpan, Ece Boran, Richard Rosch, San Pietro Lo Biundo, Georgia Ramantani (and 1 more)\nAcknowledgment: Please cite this paper: to be filled when DOI confirmed\nReferences: TBD\nDOI: 10.18112/openneuro.ds003555.v1.0.1",
        "readme": "# Dataset of EEG recordings containing HFO markings for 30 pediatric patients with epilepsy \n\n## Summary\nHigh-frequency oscillations in scalp EEG are promising non-invasive biomarkers of epileptogenicity. However, it is unclear how high-frequency oscillations are impacted by age in the pediatric population. \nWe recorded and processed the first 3 hours of sleep EEG data in 30 children and adolescents with focal or generalized epilepsy. We used an automated and clinically validated high-frequency oscillation detector to determine ripple rates (80-250 Hz) in bipolar channels. The software for the detection of HFOs is freely available at the GitHub repository (https://github.com/ZurichNCH/Automatic-High-Frequency-Oscillation-Detector). Furthermore HFO markings are also added in this database for the selected N3 intervals.\n\n\n## Repository structure\n\n### Main directory (hfo/)\nContains metadata files in the BIDS standard about the participants and the study. Folders are explained below.\n\n### Subfolders\n* hfo/sub-**/\nContains folders for each subject, named sub-<subject number> and session information.\n* hfo/sub-**/ses-01/eeg\nContains the raw eeg data in .edf format for each subject. The duration is typically 3 hours, that was recorded in the beginning of the sleep. Details about the channels are given in the corresponding .tsv file. \n* hfo/derivatives\nBesides containingsubfolders for the raw data, there are two .json files. The events_description.json explains the meaning of the columns of the event description tsv files (in the subfolders).\nThe interval_description.json explains the meaning of the columns of the interval description tsv files (in the subfolders).\n\n* hfo/derivatives/sub-**/ses-01/eeg/\nContains processed data for each subject. Based on the sleep annotations, first we identified the sleep stages. Then we cut 5 minutes data intervals from the N3 sleep stages. We applied bipolar referencing by considering all nearest neighbour chanels, thus resulting in 52 bipolar channels. Each run corresponds to one 5 minute data interval. The DataIntervals.tsv file provides information about how the various runs are related to the raw data by providing the start and end indeces. Besides the .edf and channel descriptor .tsv files there is an other .tsv file containing the detected candidate event details. Eg. sub-26_ses-01_task-hfo_run-01_events.tsv contains for subject 26 for the first processed data interval the event markings as indeces with additional features of this event described in the abovementioned events_description.json file.\n\n\n## Related materials\nThe code for HFO detection is available at https://github.com/ZurichNCH/Automatic-High-Frequency-Oscillation-Detector\n\n\n## Support\nFor questions on the dataset or the task, contact Johannes Sarnthein at [johannes.sarnthein@usz.ch](johannes.sarnthein@usz.ch).",
        "participants_overview": "age: [\"0.7\", \"0.8\", \"1.5\", \"1.6\", \"11.5\", \"11.6\", \"12.1\", \"12.4\", \"15.3\", \"15.7\" (and 10 more)]; sex: [\"f\", \"m\"]; eeg_montage: [\"10-20 system\"]",
        "tasks": [
          "hfo"
        ],
        "events": [],
        "task_details": "Task 'hfo':\nTaskDescription: detection of High-Frequency Oscillation (HFO) events on scalp EEG for studying age related changes in case of pediatric patients ",
        "openneuro_name": "Dataset of EEG recordings of pediatric patients with epilepsy based on the 10-20 system ",
        "openneuro_doi": "10.18112/openneuro.ds003555.v1.0.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 30
      }
    }
  ]
}