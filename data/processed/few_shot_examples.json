{
  "few_shot_examples": [
    {
      "dataset_id": "DS005342",
      "pathology": "Healthy",
      "modality": "Visual",
      "type": "Motor",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS005342.html",
      "openneuro_id": "ds005342",
      "openneuro_url": "https://openneuro.org/datasets/ds005342",
      "github_url": "https://github.com/OpenNeuroDatasets/ds005342",
      "eegdash_subjects": 32,
      "metadata": {
        "title": "EEG data offline and online during motor imagery for standing and sitting",
        "dataset_description": "Name: EEG data offline and online during motor imagery for standing and sitting\nAuthors: Nayid Triana-Guzman, Alvaro D Orjuela-Cañon, Andres L Jutinico, Omar Mendoza-Montoya, Javier M Antelis\nAcknowledgment: Triana-Guzman N, Orjuela-Cañon AD, Jutinico AL, Mendoza-Montoya O and Antelis JM (2024). EEG data offline and online during motor imagery for standing and sitting. OpenNeuro Dataset ds005342. doi: ...\nReferences: Triana-Guzman N, Orjuela-Cañon AD, Jutinico AL, Mendoza-Montoya O and Antelis JM (2022) Decoding EEG rhythms offline and online during motor imagery for standing and sitting based on a brain-computer interface. Front. Neuroinform. 16:961089. https://doi.org/10.3389/fninf.2022.961089\nDOI: doi:10.18112/openneuro.ds005342.v1.0.3",
        "readme": "The experiments were conducted in an acoustically isolated room where only the participant and the experimenter were present. Participants voluntarily signed an informed consent form in accordance with the experimental protocol approved by the ethics committee of the Universidad Antonio Nariño. The participant was seated in a chair in a posture that was comfortable for him/her but did not affect data collection. In front of the participant, a 40-inch TV screen was placed at about 3 m. On this screen, a graphical user interface (GUI) displayed images that guided the participant through the experiment. Each experimental session was divided into two phases: an offline phase and an online phase.\n\nThe offline experiments consisted of recording participants´ EEG signals during motor imagery trials for standing and sitting that were guided by the GUI presented on the TV screen. Six offline runs were conducted in which the participants were standing in three runs and sitting in the other three runs. In each run, the participant had to repeat a block of 30 trials of mental tasks indicated by visual cues continuously presented on the screen in a pseudo-random sequence.\n\nThe first phase of the experimental session was conducted to construct the offline parts of the dataset: (A) Sit-to-stand and (B) Stand-to-sit. The participant´s EEG data were collected from 90 sequences for part A (45 trials of MotorImageryA tasks and 45 trials of IdleStateA tasks) and 90 sequences for part B (45 trials of MotorImageryB tasks and 45 trials of IdleStateB tasks).\n\nFor each participant, the two machine learning models obtained in the offline phase were used to carry out the online experiment parts of the dataset: (C) Sit-to-stand and (D) Stand-to-sit. Each participant was instructed to select, in no particular order, 30 sequences for part C (15 trials of MotorImageryA tasks and 15 trials of IdleStateA tasks) and 30 other sequences for part D (15 trials of MotorImageryB tasks and 15 trials of IdleStateB tasks). Each trial was unique and was generated pseudo-randomly before the experiment.\n\nThe database consisted of 32 electroencephalographic files corresponding to the 32 participants. All recordings were collected on channels F3, Fz, F4, FC5, FC1, FC2, FC6, C3, Cz, C4, CP5, CP1, CP2, CP6, P3, Pz, and P4 according to the 10-20 EEG electrode placement standard, grounded to AFz channel and referenced to right mastoid (M2). Each data file contained the data stream in a 2D matrix where rows corresponded to channels and columns corresponded to time samples with a sampling frequency of 250Hz.\n\nThe following marker numbers encoded information about the execution of the experiment. Marker numbers 200, 201, 202, and 203, indicated the beginning and end of the four steps of the sequence in a trial (resting, fixation, action observation, and imagining). Marker numbers 1, 2, 3, and 4, indicated the figure activated on the screen to the participant perform the task corresponding to 1. actively imagining the sit-to-stand movement (labeled as MotorImageryA), 2. sitting motionless without imagining the sit-to-stand movement (labeled as IdleStateA), 3. standing motionless while actively imagining the stand-to-sit movement (labeled as MotorImageryB), or 4. standing motionless without imagining the stand-to-sit movement (labeled as IdleStateB). Finally, marker numbers 101, 102, 103, and 104, indicated the task detected by the BCI in real time during the online experiment: 101. MotorImageryA, 102. IdleStateA, 103. MotorImageryB, or 104. IdleStateB.",
        "participants_overview": "gender: [\"F\", \"M\"]; age: [\"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\" (and 1 more)]; handedness: [\"left_handed\", \"right_handed\"]; major: [\"industrial_automation\", \"industrial_engineering\", \"medicine\", \"nursing\"]",
        "tasks": [
          "sitstand"
        ],
        "events": [],
        "json_metadata_summary": "=== task-sitstand_events.json ===\nonset: {LongName, Description, Units}\nduration: {LongName, Description, Units}\n\n=== sub-001/eeg/sub-001_task-sitstand_eeg.json ===\nInstitutionAddress: Carrera 3 Este # 47 A - 15, Sede Circunvalar, Bogotá, Colombia\nInstitutionName: Universidad Antonio Nariño\nInstitutionalDepartmentName: Doctorado en Ciencia Aplicada\nTaskName: sitstand\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nManufacturersModelName: g.Nautilus PRO\nEEGPlacementScheme: 10-20\nEEGReference: right mastoid (M2)\nEEGGround: AFz channel\nManufacturer: g.tec\nEEGChannelCount: 17\nInstructions: First, a cross symbol was displayed on the TV screen and the participant was instructed to remain relaxed, motionless, and focused while looking at the symbol. Second, a figure appeared on the TV s...\nTaskDescription: The temporal sequence task of a trial performed by each participant consisted of four st...\n\n=== sub-002/eeg/sub-002_task-sitstand_eeg.json ===\nInstitutionAddress: Carrera 3 Este # 47 A - 15, Sede Circunvalar, Bogotá, Colombia\nInstitutionName: Universidad Antonio Nariño\nInstitutionalDepartmentName: Doctorado en Ciencia Aplicada\nTaskName: sitstand\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nManufacturersModelName: g.Nautilus PRO\nEEGPlacementScheme: 10-20\nEEGReference: right mastoid (M2)\nEEGGround: AFz channel\nManufacturer: g.tec\nEEGChannelCount: 17\nInstructions: First, a cross symbol was displayed on the TV screen and the participant was instructed to remain relaxed, motionless, and focused while looking at the symbol. Second, a figure appeared on the TV s...\nTaskDescription: The temporal sequence task of a trial performed by each participant consisted of four st...\n\n=== sub-003/eeg/sub-003_task-sitstand_eeg.json ===\nInstitutionAddress: Carrera 3 Este # 47 A - 15, Sede Circunvalar, Bogotá, Colombia\nInstitutionName: Universidad Antonio Nariño\nInstitutionalDepartmentName: Doctorado en Ciencia Aplicada\nTaskName: sitstand\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nManufacturersModelName: g.Nautilus PRO\nEEGPlacementScheme: 10-20\nEEGReference: right mastoid (M2)\nEEGGround: AFz channel\nManufacturer: g.tec\nEEGChannelCount: 17\nInstructions: First, a cross symbol was displayed on the TV screen and the participant was instructed to remain relaxed, motionless, and focused while looking at the symbol. Second, a figure appeared on the TV s...\nTaskDescription: The temporal sequence task of a trial performed by each participant consisted of four st...\n\n=== sub-004/eeg/sub-004_task-sitstand_eeg.json ===\nInstitutionAddress: Carrera 3 Este # 47 A - 15, Sede Circunvalar, Bogotá, Colombia\nInstitutionName: Universidad Antonio Nariño\nInstitutionalDepartmentName: Doctorado en Ciencia Aplicada\nTaskName: sitstand\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nManufacturersModelName: g.Nautilus PRO\nEEGPlacementScheme: 10-20\nEEGReference: right mastoid (M2)\nEEGGround: AFz channel\nManufacturer: g.tec\nEEGChannelCount: 17\nInstructions: First, a cross symbol was displayed on the TV screen and the participant was instructed to remain relaxed, motionless, and focused while looking at the symbol. Second, a figure appeared on the TV s...\nTaskDescription: The temporal sequence task of a trial performed by each participant consisted of four st...\n\n=== sub-005/eeg/sub-005_task-sitstand_eeg.json ===\nInstitutionAddress: Carrera 3 Este # 47 A - 15, Sede Circunvalar, Bogotá, Colombia\nInstitutionName: Universidad Antonio Nariño\nInstitutionalDepartmentName: Doctorado en Ciencia Aplicada\nTaskName: sitstand\nPowerLineFrequency: 60\nSoftwareFilters: {FilterDescription}\nManufacturersModelName: g.Nautilus PRO\nEEGPlacementScheme: 10-20\nEEGReference: right mastoid (M2)\nEEGGround: AFz channel\nManufacturer: g.tec\nEEGChannelCount: 17\nInstructions: First, a cross symbol was displayed on the TV screen and the participant was instructed to remain relaxed, motionless, and focused while looking at the symbol. Second, a figure appeare...",
        "openneuro_name": "EEG data offline and online during motor imagery for standing and sitting",
        "openneuro_doi": "doi:10.18112/openneuro.ds005342.v1.0.3",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.3389/fninf.2022.961089]\nMotor imagery (MI)-based brain-computer interface (BCI) systems have shown promising advances for lower limb motor rehabilitation. The purpose of this study was to develop an MI-based BCI for the actions of standing and sitting. Thirty-two healthy subjects participated in the study using 17 active EEG electrodes. We used a combination of the filter bank common spatial pattern (FBCSP) method and the regularized linear discriminant analysis (RLDA) technique for decoding EEG rhythms offline and online during motor imagery for standing and sitting. The offline analysis indicated the classification of motor imagery and idle state provided a mean accuracy of 88.51 ± 1.43% and 85.29 ± 1.83% for the sit-to-stand and stand-to-sit transitions, respectively. The mean accuracies of the sit-to-stand and stand-to-sit online experiments were 94.69 ± 1.29% and 96.56 ± 0.83%, respectively. From these results, we believe that the MI-based BCI may be useful to future brain-controlled standing systems.",
        "eegdash_subjects": 32
      }
    },
    {
      "dataset_id": "DS005207",
      "pathology": "Healthy",
      "modality": "Sleep",
      "type": "Sleep",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS005207.html",
      "openneuro_id": "ds005207",
      "openneuro_url": "https://openneuro.org/datasets/ds005207",
      "github_url": "https://github.com/OpenNeuroDatasets/ds005207",
      "eegdash_subjects": 20,
      "metadata": {
        "title": "Surrey cEEGrid sleep data set",
        "dataset_description": "Name: Surrey cEEGrid sleep data set\nAuthors: Kaare B. Mikkelsen, James K Ebajemito, Maria A Bonmati-Carrion, Nayantara Santhi, Victoria L Revell (and 7 more)\nAcknowledgment: Please cite Mikkelsen et al 2018: https://doi.org/10.1111/jsr.12786\nDOI: doi:10.18112/openneuro.ds005207.v1.0.0",
        "readme": "Surrey sleep data set\n\n**Overview**\n\nThis dataset was collected as part of a research project on wearable sleep monitoring which took place in spring 2017.\n\nThe data set contains nightly EEG recordings from 20 healthy participants ('subjects'). Some recordings are full polysomnography (PSG) measurements, others are cEEGrid measurements. Most subjects have both PSG and ceegrid recordings from the same night, though a few are missing one or the other.\n\n**Format**\n\nThe dataset is formatted according to the Brain Imaging Data Structure. See the 'dataset_description.json' file for the specific BIDS version used. The EEG data format chosen is the '.set' format of EEGLAB.\n\nFor more information, see the following link:\nhttps://bids-specification.readthedocs.io/en/stable/01-introduction.html\n\n\n**Task description**\n\nThe patient performed no tasks. The recording equipment was mounted immediately prior to bedtime, and the recordings took place at the sleep laboratory of the Surrey Clinical Research Centre.\n\nNote that due to a miscommunication during the study, alignment information between cEEGrid and PSG recordings has not been saved. This means that to obtain a useful comparison between the two methods, for instance to align the manual scoring with the cEEGrid recordings, some post processing has to be performed. In the derivative dataset, 'aligned1', we have shared our own best attempt at alignment. \n\nThe data set was previously described in the paper \n'Machine-learning-derived sleep–wake staging from around-the-ear electroencephalogram outperforms manual scoring and actigraphy', Mikkelsen et al 2018, https://doi.org/10.1111/jsr.12786\n\n**Contact**\n\nFor questions regarding this data set, contact: \nKaare Mikkelsen, Mikkelsen.kaare@ece.au.dk, https://orcid.org/0000-0002-7360-8629",
        "tasks": [
          "sleep",
          "sleep",
          "sleep",
          "sleep"
        ],
        "events": [
          "End",
          "Lights Off",
          "Lights On",
          "Marker",
          "Sleep Onset",
          "Start",
          "Unknown"
        ],
        "json_metadata_summary": "=== task-sleep_acq-psg_events.json ===\nonset: {Description}\nduration: {Description}\ntrial_type: {LongName, Levels}\n\n=== sub-001/ses-001/eeg/sub-001_ses-001_task-sleep_acq-PSG_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 128\nEEGReference: A1, A2\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 6\nEOGChannelCount: 3\nECGChannelCount: 1\nEMGChannelCount: 5\nMiscChannelCount: 0\nTriggerChannelCount: 0\nEEGPlacemen...\n\n=== sub-001/ses-001/eeg/sub-001_ses-001_task-sleep_acq-cEEGrid_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 250\nEEGReference: R4b\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 15\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 6\nTriggerChannelCount: 0\nEEGPlacem...\n\n=== sub-003/ses-001/eeg/sub-003_ses-001_task-sleep_acq-PSG_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 128\nEEGReference: A1, A2\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 6\nEOGChannelCount: 3\nECGChannelCount: 1\nEMGChannelCount: 5\nMiscChannelCount: 0\nTriggerChannelCount: 0\nEEGPlacemen...\n\n=== sub-003/ses-001/eeg/sub-003_ses-001_task-sleep_acq-cEEGrid_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 250\nEEGReference: R4b\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGChannelCount: 12\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 6\nTriggerChannelCount: 0\nEEGPlacem...\n\n=== sub-004/ses-001/eeg/sub-004_ses-001_task-sleep_acq-PSG_eeg.json ===\nTaskName: Sleep\nSamplingFrequency: 128\nEEGReference: A1, A2\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nTaskDescription: The study participants were asked to stay in bed for 12 hrs between approximately 22:00 and 10:00 hours, during which they were allowed to sleep as much as they wanted ('ad libitum').\nInstitutionName: University of Oxford\nInstitutionalDepartmentName: Oxford Institute of Biomedical Engineering\nInstitutionAddress: Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, UK\nEEGCha...",
        "openneuro_name": "Surrey cEEGrid sleep data set",
        "openneuro_doi": "doi:10.18112/openneuro.ds005207.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 20
      }
    },
    {
      "dataset_id": "DS005048",
      "pathology": "Dementia",
      "modality": "Auditory",
      "type": "Attention",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS005048.html",
      "openneuro_id": "ds005048",
      "openneuro_url": "https://openneuro.org/datasets/ds005048",
      "github_url": "https://github.com/OpenNeuroDatasets/ds005048",
      "eegdash_subjects": 35,
      "metadata": {
        "title": "40Hz Auditory Entrainment",
        "dataset_description": "Name: 40Hz Auditory Entrainment\nAuthors: Mojtaba Lahijanian, Hamid Aghajan, Zahra Vahabi\nAcknowledgment: Please cite the following article as well as dataset DOI:\nLahijanian, M., Aghajan, H. & Vahabi, Z. Auditory gamma-band entrainment enhances default mode network connectivity in dementia patients. S...\nReferences: https://doi.org/10.1038/s41598-024-63727-z; https://doi.org/10.1101/2021.09.30.462389\nDOI: doi:10.18112/openneuro.ds005048.v1.0.1",
        "readme": "Introduction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \nThis experiment was designed to entrain the brain oscillations through synthetic auditory stimulation conducted on a group of elderly suffering from dementia. Recently, gamma entrainment has been proposed and shown effective in improving several symptoms of Alzheimer's Diseases (AD). The aim of this study is to investigate the effect of entrainment on brain oscillations using EEG signal recording during the auditory brain stimulation. This study was approved by the Review Board of Tehran University of Medical Sciences (Approval ID: IR.TUMS.MEDICINE.REC.1398.524). All methods were performed in accordance with the relevant guidelines and regulations, and all participants provided informed consent before participating and were free to withdraw at any time. To accommodate participants who preferred a shorter duration of data gathering, we designed both short and long sessions for entrainment. This approach aimed to minimize inconvenience for the participants who were less inclined to engage in lengthy procedures.                                                                                                                                                                                                                                                                                     \nEntrainment session and auditory stimulation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \nEach session involved the presentation of a multi-trial auditory stimulus while simultaneou...",
        "participants_overview": "Gender: [\"Female\", \"Male\"]; Age: [\"54\", \"57\", \"59\", \"60\", \"63\", \"64\", \"65\", \"67\", \"68\", \"69\" (and 10 more)]; Group: [\"-\", \"MCI\", \"Mild AD\", \"Moderate AD\", \"Normal\"]",
        "tasks": [
          "40HzAuditoryEntrainment"
        ],
        "events": [
          "Rest",
          "Stimulus"
        ],
        "json_metadata_summary": "=== task-40HzAuditoryEntrainment_events.json ===\nduration: {LongName, Description, Units}\ntrial_type: {LongName, Description}\nresponse_time: {LongName, Description, Units}\nonset: {LongName, Description, Units}\n\n=== sub-01/eeg/sub-01_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-02/eeg/sub-02_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-03/eeg/sub-03_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-04/eeg/sub-04_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-05/eeg/sub-05_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250",
        "openneuro_name": "40Hz Auditory Entrainment",
        "openneuro_doi": "doi:10.18112/openneuro.ds005048.v1.0.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/2 - DOI: 10.1038/s41598-024-63727-z]\nAbstractDementia, and in particular Alzheimer’s disease (AD), can be characterized by disrupted functional connectivity in the brain caused by beta-amyloid deposition in neural links. Non-pharmaceutical treatments for dementia have recently explored interventions involving the stimulation of neuronal populations in the gamma band. These interventions aim to restore brain network functionality by synchronizing rhythmic energy through various stimulation modalities. Entrainment, a newly proposed non-invasive sensory stimulation method, has shown promise in improving cognitive functions in dementia patients. This study investigates the effectiveness of entrainment in terms of promoting neural synchrony and spatial connectivity across the cortex. EEG signals were recorded during a 40 Hz auditory entrainment session conducted with a group of elderly participants with dementia. Phase locking value (PLV) between different intraregional and interregional sites was examined as an attribute of network synchronization, and connectivity of local and distant links were compared during the stimulation and rest trials. Our findings demonstrate enhanced neural synchrony between the frontal and parietal regions, which are key components of the brain’s default mode network (DMN). The DMN operation is known to be impacted by dementia’s progression, leading to reduced functional connectivity across the parieto-frontal pathways. Notably, entrainment alone significantly improves synchrony between these DMN components, suggesting its potential for restoring functional connectivity.\n\n---\n\n[Paper 2/2 - DOI: 10.1101/2021.09.30.462389]\nAbstractNon-invasive gamma entrainment has shown promising results in alleviating cognitive symptoms of Alzheimer’s disease in mice and humans. In this study, we examine improvements in the synchronization characteristics of the brain’s oscillations induced by 40Hz auditory stimulation based on electroencephalography data recorded from a group of dementia patients. We observed that when the quality of entrainment surpasses a certain level, several indicators of brain synchronization significantly improve. Specifically, the entrained oscillatory activity maintains temporal phase stability in the frontal, parietal, and occipital regions, and persistent spatial phase coupling between them. In addition, notable theta-gamma phase-amplitude coupling is observed in these areas. Interestingly, a high theta power at rest predicts the quality of entrainment. We identify differentiating attributes of temporal/spatial synchronization and cross-frequency coupling in the data of two groups with entrained and non-entrained responses which point to enhanced network synchronization caused by entrainment and can explain its potential therapeutic effects.",
        "eegdash_subjects": 35
      }
    },
    {
      "dataset_id": "DS004584",
      "pathology": "Parkinson's",
      "modality": "Resting State",
      "type": "ClinicalIntervention",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004584.html",
      "openneuro_id": "ds004584",
      "openneuro_url": "https://openneuro.org/datasets/ds004584",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004584",
      "eegdash_subjects": 149,
      "metadata": {
        "title": "Rest eyes open",
        "dataset_description": "Name: Rest eyes open\nAuthors: Arun Singh arun.singh@usd.edu, Rachel Cole rachel-cole@uiowa.edu, Arturo Espinoza arturo-espinoza@uiowa.edu, Jim Cavanagh jcavanagh@unm.edu, Nandakumar Narayanan nandakumar-narayanan@uiowa.edu\nReferences: doi: https://doi.org/10.1101/2022.07.26.22278079\nDOI: doi:10.18112/openneuro.ds004584.v1.0.0",
        "readme": "This experiment includes 149 subjects: 100 individuals with Parkinsons disease, \nand 49 controls. EEG was recorded with a 64-channel BrainVision cap. Resting-state \nEEG was collected from patients sitting in a quiet room with their eyes open for \ntwo minutes.",
        "participants_overview": "GROUP: [\"Control\", \"PD\"]; AGE: [\"48\", \"52\", \"53\", \"54\", \"56\", \"57\", \"58\", \"60\", \"61\", \"62\" (and 10 more)]; GENDER: [\"F\", \"M\"]; TYPE: [\"0\", \"1\"]",
        "tasks": [],
        "events": [],
        "json_metadata_summary": "=== sub-001/eeg/sub-001_task-Rest_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/eeg/sub-001_task-Rest_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Rest\nRecordingType: continuous\nRecordingDuration: 281.66\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/eeg/sub-002_task-Rest_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-002/eeg/sub-002_task-Rest_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Rest\nRecordingType: continuous\nRecordingDuration: 326.04\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/eeg/sub-003_task-Rest_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-003/eeg/sub-003_task-Rest_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Rest\nRecordingType: continuous\nRecordingDuration: 252.36\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-004/eeg/sub-004_task-Rest_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-004/eeg/sub-004_task-Rest_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Rest\nRecordingType: continuous\nRecordingDuration: 263.96\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-005/eeg/sub-005_task-Rest_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-005/eeg/sub-005_task-Rest_eeg.json ===\nInstitutionAddress: Narayanan Lab / University of Iowa \nInstitutionName: 169 Newton Road\nInstitutionalDepartmentName: Department of Neurology\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision\nEEGGround: AFz\nEEGReference: Pz\nEEGChannelCount: 63\nTaskName: Rest\nRecordingType: continuous\nRecordingDuration: 249.54\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a",
        "openneuro_name": "Rest eyes open",
        "openneuro_doi": "doi:10.18112/openneuro.ds004584.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.1101/2022.07.26.22278079]\nAbstractCognitive dysfunction is a major feature of Parkinson’s disease (PD), but the pathophysiology remains unknown. One potential mechanism is abnormal low-frequency cortical rhythms which engage cognitive functions and are deficient in PD. We tested the hypothesis that midfrontal delta/theta rhythms predict cognitive dysfunction in PD. We recruited 100 PD patients and 49 demographically-similar control participants who completed a series of cognitive control tasks, including the Simon, oddball, and interval timing tasks. We focused on cue-evoked delta (1-4 Hz) and theta (4-7 Hz) rhythms from a single midfrontal EEG electrode (Cz) in PD patients who were either cognitively normal, with mild-cognitive impairments (PDMCI), or had dementia (PDD). We found that PD-related cognitive dysfunction was associated with increased response latencies and decreased midfrontal delta power across all tasks. Within PD patients, the first principal component of evoked EEG features from a single electrode (Cz) strongly correlated with clinical metrics such as the Montreal Cognitive Assessment (MOCA; rho=0.36) and with NIH-toolbox Executive Function scores (rho=0.46). These data demonstrate that cue-evoked midfrontal delta/theta rhythms directly relate to cognition in PD. Our results provide insight into the nature of low-frequency frontal rhythms and suggest that PD-related cognitive dysfunction results from decreased delta/theta activity. These findings could facilitate the development of new biomarkers and targeted therapies for cognitive symptoms of PD.",
        "eegdash_subjects": 149
      }
    },
    {
      "dataset_id": "DS004117",
      "pathology": "Healthy",
      "modality": "Visual",
      "type": "Memory",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004117.html",
      "openneuro_id": "ds004117",
      "openneuro_url": "https://openneuro.org/datasets/ds004117",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004117",
      "eegdash_subjects": 23,
      "metadata": {
        "title": "Sternberg Working Memory",
        "dataset_description": "Name: Sternberg Working Memory\nAuthors: Julie Onton (data), Scott Makeig (data and curation), Arnaud Delorme (data and curation), Dung Truong (curation), Kay Robbins (curation)\nAcknowledgment: Cite this paper: https://pubmed.ncbi.nlm.nih.gov/15927487/ and consider including the following message: 'This data was obtained from the OpenNeuro database. Its accession number is ds004117.'\nReferences: Onton, J., Delorme, A., and Makeig, S. (2005). Frontal midline EEG dynamics during working memory. Neuroimage 27, 241-356. https://doi.org/10.1016/j.neuroimage.2005.04.014.\nDOI: doi:10.18112/openneuro.ds004117.v1.0.1",
        "readme": "## Modified Sternberg Working Memory Experiment\n\n**Project name:** EEG and working memory\n\n**Years the project ran:** 2004-05\n\n**Brief overview of experiment task:** The purpose of this Modified Sternberg task study was to\nexplore source-resolved EEG brain dynamics associated with selectively committing a series of letters to memory,\nthen after a brief maintenance period responding by button press either yes or no to the question of whether\na presented query letter had been in the just-presented set of to-be-memorized letters.\n\nThe task is a modified version of the classic Sternberg working memory task, with two added features:\n(1) interspersing the sequence of presented (black) letters to be memorized with (green) letters to be ignored,\nand (2) delivering auditory feedback on each trial as to the correctness of the participant response\n(beep = correct, buzz = incorrect).\n\n**Data collection:** Scalp EEG data were collected from 71 scalp electrode channels,\neach referred to a right mastoid electrode, at a sampling rate of 250 Hz/channel within an\nanalog passband of 0.1 to 100 Hz.\n\n**Contact person:   Julie Onton <julieonton@gmail.com>, ORCID#:0000-0002-5602-3557.\n\n**Access information:**  Contributed to OpenNeuro.org and NEMAR.org in BIDS format\nfollowing annotation using HED 8.0.0 in April, 2022.\n\n**Independent variables:** Letter category (to_memorize, to_ignore);\nnumbers of presented letters to_memorize/to_ignore (3/5, 5/3, 7/1);\nprobe letter category (in/not in the presented set). Note, only letters to be memorized appear as in set probe letters.\n\n**Dependent variables:**  EEG; button press response latency;  participant response (correct/incorrect).\n\n**Participant pool:** The dataset includes data collected from 23 healthy young adult subjects\n(7 male, 6 female, 11 unidentified) between the ages of 19 and 40 years of age.\n\n**Apparatus:** A Neurobehavioral Systems, Inc. EEG system running under Window98 acquired the data.\nThe experiment control program was Presentation (Neurobehavioral Systems, Inc.).\n\n**Initial setup:** EEG data were collected from 71 channels (69 scalp and two periocular electrodes,\nall referred to right mastoid) with an analog pass band of 0.01 to 100 Hz (SA Instrumentation, San Diego).\nInput impedances were brought under 5 kOhms by careful scalp preparation.\n\nData for subjects 1-12 was acquired at a sampling rate of 250Hz. The data for subject 14 was acquired at\n1000 Hz and the data for subjects 15-24 was a acquired using a 500 Hz sampling rate.\n\n**Task organization:**  Data was organized into runs of 25 trials each followed by a rest.\nEach block was a separate run in the BIDS dataset.\n\n**Task details:** Each trial consisted of the following sequence of events:\n\n**[Trial initiation]**. After a self-selected, variable delay,\nthe subject initiated the next trial by pressing either response button,\ntriggering the reappearance of the fixation cross.\n\n**[Letter sequence presentation]**. In these experiments, following a 5s presentation of a central\nfixation cross cue, a series of 8 visual letters (~2 deg of visual angle) were presented at\nscreen center for 1.2s followed by a 0.2s ISI:\n\n- Either 3, 5, or 7 of these were colored black.\n- The participant was to memorize as letters in this set.\n- The other 5, 3, or 1 letters in the sequence were colored green and participants were to ignore these.\n- The letters were drawn without substitution from the English alphabet (omitting only A, E, I, O, and U).\n- The presentation order of black and green letters was pseudo-random.\n\n**[Memory maintenance]**. In place of a ninth letter, a dash appeared on the screen to signal the\nbeginning of a Memory Maintenance period lasting between 2 to 4 s.\nDuring this period subjects were to silently rehearse the identities of the memorized letters.\n\n**[Memory probe]**. A (red) probe letter then appeared, prompting the subject to respond by\npressing one of two buttons (with the thumb or index finger of their dominant hand)\nto indi...",
        "participants_overview": "age: [\"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"28\", \"32\" (and 2 more)]; sex: [\"F\", \"M\"]",
        "tasks": [
          "WorkingMemory",
          "WorkingMemory"
        ],
        "events": [
          "left_click",
          "right_click",
          "show_cross",
          "show_dash",
          "show_letter",
          "sound_beep",
          "sound_buzz"
        ],
        "json_metadata_summary": "=== code/task-WorkingMemory_events.json ===\nevent_type: {Levels, HED}\n\n=== task-WorkingMemory_events.json ===\nevent_type: {Levels, HED}\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-1_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-1_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 652.952\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-2_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-2_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 615.048\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-3_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-3_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 617.024\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-4_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-WorkingMemory_run-4_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 583.284\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-1_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-1_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 724.484\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-2_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-2_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 762.98\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-3_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-3_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 764.904\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-4_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-WorkingMemory_run-4_eeg.json ===\nTaskName: WorkingMemory\nEEGReference: common\nRecordingType: continuous\nRecordingDuration: 725.416\nSamplingFrequency: 250.0\nEEGChannelCount: 69\nEOGChannelCount: 2\nPowerLineFrequency: 60\nSoftwareFilters: n/a\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-WorkingMemory_run-1_coordsystem.json ===\nEEGCoordinateUnits: n/a\nEEGCoordinateSystem: CTF\nEEGCoordinateSystemDescription: EEGLAB\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_ta...",
        "openneuro_name": "Sternberg Working Memory",
        "openneuro_doi": "doi:10.18112/openneuro.ds004117.v1.0.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.1016/j.neuroimage.2005.04.014]\nWe show that during visual working memory, the electroencephalographic (EEG) process producing 5-7 Hz frontal midline theta (fmtheta) activity exhibits multiple spectral modes involving at least three frequency bands and a wide range of amplitudes. The process accounting for the fmtheta increase during working memory was separated from 71-channel data by clustering on time/frequency transforms of components returned by independent component analysis (ICA). Dipole models of fmtheta component scalp maps were consistent with their generation in or near dorsal anterior cingulate cortex. From trial to trial, theta power of fmtheta components varied widely but correlated moderately with theta power in other frontal and left temporal processes. The weak mean increase in frontal midline theta power with increasing memory load, produced entirely by the fmtheta components, largely reflected progressively stronger theta activity in a relatively small proportion of trials. During presentations of letter series to be memorized or ignored, fmtheta components also exhibited 12-15 Hz low-beta activity that was stronger during memorized than during ignored letter trials, independent of letter duration. The same components produced a brief 3-Hz burst 500 ms after onset of the Probe letter following each letter sequence. A new decomposition method, log spectral ICA, applied to normalized log time/frequency transforms of fmtheta component Memorize-letter trials, showed that their low-beta activity reflected harmonic energy in continuous, sharp-peaked theta wave trains as well as independent low-beta bursts. Possibly, the observed fmtheta process variability may index dynamic adjustments in medial frontal cortex to trial-specific behavioral context and task demands.",
        "eegdash_subjects": 23
      }
    },
    {
      "dataset_id": "DS003555",
      "pathology": "Epilepsy",
      "modality": "Resting State",
      "type": "ClinicalIntervention",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS003555.html",
      "openneuro_id": "ds003555",
      "openneuro_url": "https://openneuro.org/datasets/ds003555",
      "github_url": "https://github.com/OpenNeuroDatasets/ds003555",
      "eegdash_subjects": 30,
      "metadata": {
        "title": "Dataset of EEG recordings of pediatric patients with epilepsy based on the 10-20 system ",
        "dataset_description": "Name: Dataset of EEG recordings of pediatric patients with epilepsy based on the 10-20 system \nAuthors: Dorottya Cserpan, Ece Boran, Richard Rosch, San Pietro Lo Biundo, Georgia Ramantani (and 1 more)\nAcknowledgment: Please cite this paper: to be filled when DOI confirmed\nReferences: TBD\nDOI: 10.18112/openneuro.ds003555.v1.0.1",
        "readme": "# Dataset of EEG recordings containing HFO markings for 30 pediatric patients with epilepsy \n\n## Summary\nHigh-frequency oscillations in scalp EEG are promising non-invasive biomarkers of epileptogenicity. However, it is unclear how high-frequency oscillations are impacted by age in the pediatric population. \nWe recorded and processed the first 3 hours of sleep EEG data in 30 children and adolescents with focal or generalized epilepsy. We used an automated and clinically validated high-frequency oscillation detector to determine ripple rates (80-250 Hz) in bipolar channels. The software for the detection of HFOs is freely available at the GitHub repository (https://github.com/ZurichNCH/Automatic-High-Frequency-Oscillation-Detector). Furthermore HFO markings are also added in this database for the selected N3 intervals.\n\n\n## Repository structure\n\n### Main directory (hfo/)\nContains metadata files in the BIDS standard about the participants and the study. Folders are explained below.\n\n### Subfolders\n* hfo/sub-**/\nContains folders for each subject, named sub-<subject number> and session information.\n* hfo/sub-**/ses-01/eeg\nContains the raw eeg data in .edf format for each subject. The duration is typically 3 hours, that was recorded in the beginning of the sleep. Details about the channels are given in the corresponding .tsv file. \n* hfo/derivatives\nBesides containingsubfolders for the raw data, there are two .json files. The events_description.json explains the meaning of the columns of the event description tsv files (in the subfolders).\nThe interval_description.json explains the meaning of the columns of the interval description tsv files (in the subfolders).\n\n* hfo/derivatives/sub-**/ses-01/eeg/\nContains processed data for each subject. Based on the sleep annotations, first we identified the sleep stages. Then we cut 5 minutes data intervals from the N3 sleep stages. We applied bipolar referencing by considering all nearest neighbour chanels, thus resulting in 52 bipolar channels. Each run corresponds to one 5 minute data interval. The DataIntervals.tsv file provides information about how the various runs are related to the raw data by providing the start and end indeces. Besides the .edf and channel descriptor .tsv files there is an other .tsv file containing the detected candidate event details. Eg. sub-26_ses-01_task-hfo_run-01_events.tsv contains for subject 26 for the first processed data interval the event markings as indeces with additional features of this event described in the abovementioned events_description.json file.\n\n\n## Related materials\nThe code for HFO detection is available at https://github.com/ZurichNCH/Automatic-High-Frequency-Oscillation-Detector\n\n\n## Support\nFor questions on the dataset or the task, contact Johannes Sarnthein at [johannes.sarnthein@usz.ch](johannes.sarnthein@usz.ch).",
        "participants_overview": "age: [\"0.7\", \"0.8\", \"1.5\", \"1.6\", \"11.5\", \"11.6\", \"12.1\", \"12.4\", \"15.3\", \"15.7\" (and 10 more)]; sex: [\"f\", \"m\"]; eeg_montage: [\"10-20 system\"]",
        "tasks": [
          "hfo"
        ],
        "events": [],
        "task_details": "Task 'hfo':\nTaskDescription: detection of High-Frequency Oscillation (HFO) events on scalp EEG for studying age related changes in case of pediatric patients ",
        "openneuro_name": "Dataset of EEG recordings of pediatric patients with epilepsy based on the 10-20 system ",
        "openneuro_doi": "10.18112/openneuro.ds003555.v1.0.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 30
      }
    },
    {
      "dataset_id": "DS003522",
      "pathology": "TBI",
      "modality": "Auditory",
      "type": "Decision-making",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS003522.html",
      "openneuro_id": "ds003522",
      "openneuro_url": "https://openneuro.org/datasets/ds003522",
      "github_url": "https://github.com/OpenNeuroDatasets/ds003522",
      "eegdash_subjects": 96,
      "metadata": {
        "title": "EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI",
        "dataset_description": "Name: EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI\nAuthors: James F Cavanagh, Davin Quinn\nReferences: PMID: 31228481\nDOI: 10.18112/openneuro.ds003522.v1.1.0",
        "readme": "3 stimulus auditory oddball data in control, sub-acute mild TBI, and chronic TBI.   Rest data is also included.   3AOB data published here: 10.1016/j.neuropsychologia.2019.107125.  FYI, same task as this different dataset: https://openneuro.org/datasets/ds003490/versions/1.1.0.   For CTL and sub-acute mTBI: Session 1 was from 3 to 14 days post-injury and was the only session with MRI. (MRI will be uploaded ...later).  Session 2 was ~2 months (1.5 to 3) and Session 3 was ~4 months (3 to 5) following Session 1.   For Chronic TBI, there was only one session for this study.   There was A LOT of subject attrition over timepoints.   Same samples as reported here: https://psycnet.apa.org/record/2020-66677-001   https://pubmed.ncbi.nlm.nih.gov/31344589/   https://pubmed.ncbi.nlm.nih.gov/31368085/  Task included in Matlab programming language.   Data collected 2016-2018 in the Center for Brain Recovery and Repair at the UNM Health Sciences Center.  Check the .xls sheet under code folder for *LOTS* more meta data.   Analysis scripts are included to re-create the paper.  - James F Cavanagh 02/17/2021",
        "participants_overview": "sex: [\"0\", \"1\"]; age: [\"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\" (and 10 more)]; Group: [\"0\", \"1\", \"2\"]",
        "tasks": [],
        "events": [
          "Eyes Closed: Every 1000 ms",
          "Eyes Open: Every 1000 ms",
          "Novel Tone",
          "STATUS",
          "Standard Tone",
          "Target Tone"
        ],
        "json_metadata_summary": "=== sub-001/ses-01/eeg/sub-001_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 965.05\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-001/ses-01/eeg/sub-001_ses-01_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 1523.3\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-01/eeg/sub-002_ses-01_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 1053.25\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-002/ses-02/eeg/sub-002_ses-02_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscChannelCount: 65\nRecordingType: continuous\nRecordingDuration: 962.7\nSamplingFrequency: 500\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nSoftwareFilters: n/a\n\n=== sub-003/ses-01/eeg/sub-003_ses-01_task-ThreeStimAuditoryOddball_events.json ===\nonset: {Description, Units}\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-ThreeStimAuditoryOddball_coordsystem.json ===\nEEGCoordinateUnits: mm\nEEGCoordinateSystem: Other\nEEGCoordinateSystemDescription: This is a bug so just ignore; it is actually ARS\n\n=== sub-004/ses-01/eeg/sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg.json ===\nInstitutionName: University of New Mexico\nInstitutionalDepartmentName: Center for Brain Recovery and Repair\nPowerLineFrequency: 60\nManufacturersModelName: Brain Vision ActiChamp\nEEGGround: AFz\nEEGReference: CPz\nEEGChannelCount: 64\nTaskName: ThreeStimAuditoryOddball\nMiscC...",
        "openneuro_name": "EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI",
        "openneuro_doi": "10.18112/openneuro.ds003522.v1.1.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 96
      }
    },
    {
      "dataset_id": "DS004356",
      "pathology": "Healthy",
      "modality": "Auditory",
      "type": "Perception",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004356.html",
      "openneuro_id": "ds004356",
      "openneuro_url": "https://openneuro.org/datasets/ds004356",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004356",
      "eegdash_subjects": 22,
      "metadata": {
        "title": "Subcortical responses to music and speech are alike while cortical responses diverge",
        "dataset_description": "Name: Subcortical responses to music and speech are alike while cortical responses diverge\nAuthors: Tong Shan, Madeline S. Cappelloni, Ross K. Maddox\nReferences: Shan, T., Cappelloni, M.S. & Maddox, R.K. Subcortical responses to music and speech are alike while cortical responses diverge. Sci Rep 14, 789 (2024). https://doi.org/10.1038/s41598-023-50438-0\nDOI: doi:10.18112/openneuro.ds004356.v2.2.1",
        "readme": "# README\n\n## Details related to access to the data\n\nPlease contact the following authors for further information:\n- Tong Shan (email: tshan@ur.rochester.edu)\n- Ross K. Maddox (email: rmaddox@ur.rochester.edu)\n\n## Overview\n\nThe goal of this study is to derive Auditory Brainstem Response (ABR) from continuous music and speech stimuli using deconvolution method. Data collected from Jun to Aug, 2021.\n\nThe details of the experiment can be found at Shan et al. (2024). There were two phases in this experiment. For the first phase, ten trials of one-minute clicks were presented to the subjects. For the second phase, the 12 types (six genres of music and six types of speech) of 12 s stimuli clips were presented. There were 40 trials \nfor each type with shuffled order. Between trials, there was a 0.5 s pause. \n\nThe code for stimulus preprocessing and EEG analysis is available on Github: \n\nhttps://github.com/maddoxlab/Music_vs_Speech_abr\n\n\n## Format\n\nThis dataset is formatted according to the EEG Brain Imaging Data Structure. It includes EEG recording from subject 001 to subject 024 (excluding subject 014 and subject 021) in raw brainvision format (including `.eeg`, `.vhdr`, and `.vmrk` triplet) and stimuli files in format of `.wav`. \n\nFor some subjects (sub-03 & sub-19), there are 2 \"runs\" of data that the first run (`run-01`) only contains the click phase (phase 1), and the second run includes the data for the ABR analysis. \n\nTriggers with values of \"1\" were recorded to the onset of the stimulus, and shortly after triggers with values of \"4\" or \"8\" were stamped to indicate the stimulus types and the trial number out of 40. This was done by converting the decimal trial number to bits, denoted b, then calculating 2 ** (b + 2). Triggers of \"999\" denote the start of a new segment of EEG. We've specified these trial numbers and more metadata of the events in each of the `*_eeg_events.tsv` file, which is sufficient to know which trial corresponded to which type of stimulus and which file.\n\n\n## Subjects\n\n24 subjects participated in this study.\n\n**Subject inclusion criteria**\n1. Age between 18-40.\n2. Normal hearing: audiometric thresholds of 20 dB HL or better from 500 to 8000 Hz.\n3. Speak English as their primary language.\n4. Self-reported normal or correctable to normal vision.\n\n**Subject exclusion criteria**\n1. Subject 014 self-withdrew partway through the experiment.\n2. Subject 021 was excluded because of technical problems during data collection that led to unusable data.\n\nTherefore, after excluding the two subjects, there were 22 subjects (11 male and 11 female) with an age of 22.7 ± 5.1 (mean ± SD) years that we included in the analysis. Please see `subjects.tsv` for more demography.\n\n## Apparatus\n\nSubjects were seated in a sound-isolating booth on a chair in front of a 24-inch BenQ monitor with a viewing distance of approximately 60 cm. Stimuli were presented at an average level of 65 dB SPL and a sampling rate of 48000 Hz through ER-2 insert earphones plugged into an RME Babyface Pro digital sound card. The stimulus presentation for the experiment was controlled by a python script using a custom package, `expyfun`.",
        "participants_overview": "gender: [\"Female\", \"Male\"]; age: [\"19\", \"20\", \"22\", \"23\", \"25\", \"28\", \"30\", \"35\", \"37\"]; tonal_language_speaker: [\"No\", \"Yes\"]; L_500: [\"0\", \"10\", \"15\", \"5\"]; L_1000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; L_2000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; L_3000: [\"-5\", \"0\", \"10\", \"5\"]; L_4000: [\"0\", \"10\", \"20\", \"5\"]; L_6000: [\"0\", \"10\", \"15\", \"5\"]; L_8000: [\"0\", \"10\", \"15\", \"5\"]; R_500: [\"0\", \"10\", \"5\"]; R_1000: [\"0\", \"10\", \"15\", \"5\"]; R_2000: [\"-5\", \"0\", \"10\", \"5\"]; R_3000: [\"-5\", \"0\", \"5\"]; R_4000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; R_6000: [\"0\", \"10\", \"20\", \"5\"]; R_8000: [\"-5\", \"0\", \"10\", \"15\", \"5\"]; note: [\"EEG 2 runs\"]",
        "tasks": [
          "MusicvsSpeech",
          "MusicvsSpeech"
        ],
        "events": [
          "acoustic",
          "chn_aud",
          "classical",
          "click",
          "eng_aud",
          "hiphop",
          "interview",
          "jazz",
          "lecture",
          "metal",
          "news",
          "pop",
          "talk"
        ],
        "task_details": "Task 'MusicvsSpeech':\nTaskName: MusicvsSpeech\nTaskDescription: For the first phase, subjects listened to 10 trials (each 60 seconds long) clicks. For the second phase, subjects listened to 40 trials (each 12 seconds long) each of six genres of music and six types of speech (480 trials in total), while seated in a sound-isolating booth on a chair in front of a monitor. Subjects were encouraged to rest or sleep and did not have to pay attention to the audio. Subjects were asked to stay awake and paying attention to the sounds.",
        "json_metadata_summary": "=== task-MusicvsSpeech_events.json ===\nonset: {Description, Units}\nduration: {Description, Units}\ntrial_type: {Description, Levels}",
        "openneuro_name": "Subcortical responses to music and speech are alike while cortical responses diverge",
        "openneuro_doi": "doi:10.18112/openneuro.ds004356.v2.2.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.1038/s41598-023-50438-0]\nAbstractMusic and speech are encountered daily and are unique to human beings. Both are transformed by the auditory pathway from an initial acoustical encoding to higher level cognition. Studies of cortex have revealed distinct brain responses to music and speech, but differences may emerge in the cortex or may be inherited from different subcortical encoding. In the first part of this study, we derived the human auditory brainstem response (ABR), a measure of subcortical encoding, to recorded music and speech using two analysis methods. The first method, described previously and acoustically based, yielded very different ABRs between the two sound classes. The second method, however, developed here and based on a physiological model of the auditory periphery, gave highly correlated responses to music and speech. We determined the superiority of the second method through several metrics, suggesting there is no appreciable impact of stimulus class (i.e., music vs speech) on the way stimulus acoustics are encoded subcortically. In this study’s second part, we considered the cortex. Our new analysis method resulted in cortical music and speech responses becoming more similar but with remaining differences. The subcortical and cortical results taken together suggest that there is evidence for stimulus-class dependent processing of music and speech at the cortical but not subcortical level.",
        "eegdash_subjects": 22
      }
    },
    {
      "dataset_id": "DS003846",
      "pathology": "Healthy",
      "modality": "Multisensory",
      "type": "Decision-making",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS003846.html",
      "openneuro_id": "ds003846",
      "openneuro_url": "https://openneuro.org/datasets/ds003846",
      "github_url": "https://github.com/OpenNeuroDatasets/ds003846",
      "eegdash_subjects": 19,
      "metadata": {
        "title": "Prediction Error",
        "dataset_description": "Name: Prediction Error\nAuthors: Lukas Gehrke, Sezen Akman, Albert Chen, Pedro Lopes, Klaus Gramann\nAcknowledgment: See CITATION.cff\nReferences: \nDOI: doi:10.18112/openneuro.ds003846.v2.0.2",
        "readme": "# Readme\n\nIn case of any questions, please contact: Lukas Gehrke, lukas.gehrke@tu-berlin.de, orcid: 0000-0003-3661-1973\n\n## Overview\n\nCyber-Physical Systems: Prediction Error\n\nThese data were collected at https://www.tu.berlin/bpn. Data collection occurred either between 10:00 and 12:00 or between 14:00 and 18:00.\n\nTo learn about the task, independent-, dependent-, and control variables, please consult the methods sections of the following two publications:\n\nhttps://dl.acm.org/doi/abs/10.1145/3290605.3300657\nhttps://iopscience.iop.org/article/10.1088/1741-2552/ac69bc/meta\n\n- Contents of the dataset: Output from BIDS-validator\n\nSummary\n324 Files, 9.76GB\n19 - Subjects\n5 - Sessions\n\nAvailable Tasks\nPredictionError\n\nAvailable Modalities\nEEG\n\n- [ ] Quality assessment of the data: Link to data paper, once done\n\n## Methods\n\n### Subjects\n\nThe study sample consists of 19 participants (participant_id 1 to 19) with ages ranging from 18 to 34 years and varying cap sizes from 54 to 60. Stimulation is delivered in three blocks: Block_1, Block_2, and Block_3, utilizing different combinations of Visual, Vibro, and EMS.\n\nParticipant Information:\nAge: Ranges from 18 to 34 years.\nCap Size: Varied, with sizes ranging from 54 to 60.\nStimulation Blocks:\nBlock_1 and Block_2 include Visual, Visual + Vibro, and Visual + Vibro + EMS.\nBlock_3 primarily involves Visual + Vibro + EMS.\nUsage of Stimulation Blocks:\nMost participants experience Visual stimulation in all blocks.\nVisual + Vibro is common in Block_1 and Block_2.\nVisual + Vibro + EMS is prevalent in Block_3.\nSome participants did not experience certain blocks (indicated by \"0\").\nOther Observations:\nCap size variation doesn't show a clear pattern in relation to stimulation blocks.\nParticipants exhibit diverse stimulation patterns, showcasing individualized experiences.\n\n### Task, Environment and Variables\n\nThis set of variables outlines key parameters in a neuroscience experiment involving a haptic task. Here's a summary:\n\nbox:\nDescription: Represents the target object to be touched following its spawn.\nUnits: String (presumably indicating the characteristics or identity of the object).\nnormal_or_conflict:\nDescription: Describes the behavior of the target object in the current trial, distinguishing between oddball and non-oddball conditions.\nUnits: String (presumably indicating the nature of the trial).\ncondition:\nDescription: Indicates the level of haptic realism in the experiment.\nUnits: String (presumably representing different levels of realism).\ncube:\nDescription: Specifies the position of the target object, whether it is located on the left, right, or center.\nUnits: String (presumably indicating spatial orientation).\ntrial_nr:\nDescription: Denotes the number of the current trial in the experiment.\nUnits: Integer.\n\n### Apparatus\n\nHere's a summary of the recording environment:\n\n- **EEG Stream Name:** BrainVision\n- **EEG Reference and Ground:** FCz and AFz, respectively\n- **EEG Channel Locations:** 63 channels with specific names (e.g., Fp1, Fz, Pz) and types (EEG)\n- **Additional Channels:** 1 EOG (Electrooculogram)\n- **Power Line Frequency:** 50 Hz\n- **Manufacturer:** Brain Products\n- **Manufacturer's Model Name:** BrainAmp DC\n- **Cap Manufacturer:** EasyCap\n- **Cap Model Name:** actiCap 64ch CACS-64\n- **EEG Placement Scheme:** Positions chosen from a 10% system\n- **Channel Counts:**\n  - EEG Channels: 63\n  - EOG Channels: 1\n  - ECG Channels: 0\n  - EMG Channels: 0\n  - Miscellaneous Channels: 0\n  - Trigger Channels: 0\n\nThis configuration indicates a high-density EEG setup with specific electrode placements, utilizing Brain Products' BrainAmp DC model. The electrode cap is manufactured by EasyCap, with the specific model name actiCap 64ch CACS-64. The EEG data is sampled at an unspecified frequency, and the system is designed to capture electrical brain activity across a comprehensive set of channels. The recording includes an additional channel for recording eye movements (EOG). Overall, the...",
        "participants_overview": "age: [\"18\", \"24\", \"25\", \"26\", \"27\", \"28\", \"31\", \"32\", \"34\"]; cap_size: [\"54\", \"55\", \"56\", \"58\", \"60\"]; block_1: [\"Visual\", \"Visual + Vibro\"]; block_2: [\"Visual\", \"Visual + Vibro\"]; block_3: [\"0\", \"Visual + Vibro + EMS\"]",
        "tasks": [
          "PredictionError"
        ],
        "events": [],
        "json_metadata_summary": "=== task-PredictionError_events.json ===\ncondition: {Description, Units}\nonset: {Description, Units}\nduration: {Description, Units}\n\n=== sub-02/ses-EMS/eeg/sub-02_ses-EMS_task-PredictionError_eeg.json ===\nCapManufacturer: EasyCap\nCapManufacturersModelName: actiCap 64ch CACS-64\nEEGChannelCount: 63\nEEGGround: Fpz\nEEGPlacementScheme: Positions chosen from 10% system\nEEGReference: FCz\nEOGChannelCount: 1\nInstitutionAddress: Fasanenstr. 1, 10623 Berlin\nInstitutionName: Institute for Psychology and Ergonomics\nInstitutionalDepartmentName: Biological Psychology and Neuroergonomics\nInstructions: \nManufacturer: Brain Products\nManufacturersModelName: BrainAmp DC\nPowerLineFrequency: 50\nRecordingDuration: 516.0664318\nSamplingFrequency: 500\nSoftwareFilters: n/a\nTaskDescription: Select an Object in VR by tapping on it with the fingertip of the index finger\nTaskName: PredictionError\n\n=== sub-02/ses-EMS/motion/sub-02_ses-EMS_task-PredictionError_tracksys-HTCViveHead_motion.json ===\nDeviceSerialNumber: n/a\nExternalSoftwareVersions: n/a\nInstitutionAddress: Fasanenstr. 1, 10623 Berlin\nInstitutionName: Institute for Psychology and Ergonomics\nInstitutionalDepartmentName: Biological Psychology and Neuroergonomics\nInstructions: \nManufacturer: HTC\nManufacturersModelName: Vive\nMotionChannelCount: 7\nORNTChannelCount: 3\nPOSChannelCount: 3\nRecordingDuration: 513.4164328\nRecordingType: continuous\nRotationOrder: n/a\nRotationRule: n/a\nSamplingFrequency: 90\nSamplingFrequencyEffective: 89.44396219\nSoftwareVersions: \nSpatialAxes: n/a\nTaskDescription: Select an Object in VR by tapping on it with the fingertip of the index finger\n\n=== sub-02/ses-EMS/motion/sub-02_ses-EMS_task-PredictionError_tracksys-HTCViveRightHand_motion.json ===\nDeviceSerialNumber: n/a\nExternalSoftwareVersions: n/a\nInstitutionAddress: Fasanenstr. 1, 10623 Berlin\nInstitutionName: Institute for Psychology and Ergonomics\nInstitutionalDepartmentName: Biological Psychology and Neuroergonomics\nInstructions: \nManufacturer: HTC\nManufacturersModelName: Vive\nMotionChannelCount: 7\nORNTChannelCount: 3\nPOSChannelCount: 3\nRecordingDuration: 513.4164497\nRecordingType: continuous\nRotationOrder: n/a\nRotationRule: n/a\nSamplingFrequency: 90\nSamplingFrequencyEffective: 89.44395924\nSoftwareVersions: \nSpatialAxes: n/a\nTaskDescription: Select an Object in VR by tapping on it with the fingertip of the index finger\n\n=== sub-02/ses-Vibro/eeg/sub-02_ses-Vibro_task-PredictionError_eeg.json ===\nCapManufacturer: EasyCap\nCapManufacturersModelName: actiCap 64ch CACS-64\nEEGChannelCount: 63\nEEGGround: Fpz\nEEGPlacementScheme: Positions chosen from 10% system\nEEGReference: FCz\nEOGChannelCount: 1\nInstitutionAddress: Fasanenstr. 1, 10623 Berlin\nInstitutionName: Institute for Psychology and Ergonomics\nInstitutionalDepartmentName: Biological Psychology and Neuroergonomics\nInstructions: \nManufacturer: Brain Products\nManufacturersModelName: BrainAmp DC\nPowerLineFrequency: 50\nRecordingDuration: 1677.542133\nSamplingFrequency: 500\nSoftwareFilters: n/a\nTaskDescription: Select an Object in VR by tapping on it with the fingertip of the index finger\nTaskName: PredictionError\n\n=== sub-02/ses-Vibro/motion/sub-02_ses-Vibro_task-PredictionError_tracksys-HTCViveHead_motion.json ===\nDeviceSerialNumber: n/a\nExternalSoftwareVersions: n/a\nInstitutionAddress: Fasanenstr. 1, 10623 Berlin\nInstitutionName: Institute for Psychology and Ergonomics\nInstitutionalDepartmentName: Biological Psychology and Neuroergonomics\nInstructions: \nManufacturer: HTC\nManufacturersModelName: Vive\nMotionChannelCount: 7\nORNTChannelCount: 3\nPOSChannelCount: 3\nRecordingDuration: 1677.440104\nRecordingType: continuous\nRotationOrder: n/a\nRotationRule: n/a\nSamplingFrequency: 90\nSamplingFrequencyEffective: 89.48993149\nSoftwareVersions: \nSpatialAxes: n/a\nTaskDescription: Select an Object in VR by tapping on it with the fingertip of the index finger\n\n=== sub-02/ses-Vibro/motion/sub-02_ses-Vibro_task-PredictionError_tracksys-HTCViveRightHand_motion.json ===\nDeviceSerialNumber: n/a\nEx...",
        "openneuro_name": "Prediction Error",
        "openneuro_doi": "doi:10.18112/openneuro.ds003846.v2.0.2",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 19
      }
    },
    {
      "dataset_id": "DS004381",
      "pathology": "Surgery",
      "modality": "Other",
      "type": "Other",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004381.html",
      "openneuro_id": "ds004381",
      "openneuro_url": "https://openneuro.org/datasets/ds004381",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004381",
      "eegdash_subjects": 18,
      "metadata": {
        "title": "Intraoperative EEG dataset during medianus-tibialis stimulation with 8 different rates",
        "dataset_description": "Name: Intraoperative EEG dataset during medianus-tibialis stimulation with 8 different rates\nAuthors: Giorgio Selmin, Vasileios Dimakopoulos, Niklaus Krayenbühl, Luca Regli, Johannes Sarnthein\nAcknowledgment: If you use this dataset please cite this paper: Dimakopoulos V, Selmin G, Regli L, Sarnthein J, Optimization of signal-to-noise ratio in short-duration SEP recordings by variation of stimulation ra...\nReferences: https://hfozuri.ch\nDOI: doi:10.18112/openneuro.ds004381.v1.0.2",
        "readme": "# Intraoperative EEG dataset during medianus-tibialis stimulation with 8 different rates\nThis dataset was obtained from the publication [1] wherein we varyied the stimulus repetition rate and recorded medianus and tibial nerve SEP. \nWe randomly sampled a number of sweeps corresponding to recording durations up to 20 s and calculated the signal-to-noise ratio (SNR).\n\nThere are 14 adults subjects and 4 children subjects with continuous EEG data split in sessions (tibial left/right, medianus left/right) and runs (1 run for each stimulation rate).\nWe also provide processed data (derivatives) for all the sessions. \nIn total there are 34 medianus SEP and 32 tibial SEP sessions.\n \n## Repository structure\n\n### Main directory (SEP rate/)\nContains metadata files in the BIDS standard about the participants and the study. Folders are explained below.\n\n### Subfolders\n* SEP rate/sub-**/\nContains folders for each subject, named sub-<subject number> and session information.\n* SEP rate/sub-**/ses-01/eeg\nContains the raw eeg data in .edf format for each subject. \nEach *eeg.edf file contains EEG data from one stimulation rate (see scans.tsv column stimRate).\nDetails about the channels are given in the corresponding .tsv file. \n* SEP rate/derivatives\nContains folders for each subject,named sub-<subject number> and session information that include processed data\n* SEP rate/derivatives/sub-**/ses-01/eeg/\nContains processed data for each subject.\n\n\n# Note from the paper\n\"The offline data processing used the continuous EEG that was recorded in parallel to the SEP recordings. \nData analysis was performed with custom scripts in Matlab (www.mathworks.com). To detect the SEP stimulation artefact, \nwe first filtered the EEG (high pass cutoff = 200 Hz) and performed local peak detection (minimum peak prominence between peaks = 30 ms,\nminimum peak width = 4 ms, samples = 0.2 ms). We used the times of the detected stimulus artifact as triggers to define sweeps with \npost-stimulus recording sweep length 50 ms for medianus SEP and 100 ms for tibial SEP. We resampled the data to sampling rate 1200 Hz before\nfurther processing. We classified sweeps with amplitude > 10 ÂµV as artefact-ridden and excluded them from further analysis.\"\n\nBIDS Conversion\n---------------\nbids-starter-kid and custom Matlab scripts were used to convert the dataset into BIDS format. \n\n\nReferences\n----------\n[1] Dimakopoulos V, Selmin G, Regli L, Sarnthein J, Optimization of signal-to-noise ratio in short-duration SEP recordings by variation of stimulation rate, Clinical Neurophysiology, 2023, ISSN 1388-2457, https://doi.org/10.1016/j.clinph.2023.03.008.",
        "participants_overview": "age: [\"14\", \"29\", \"30\", \"31\", \"37\", \"4\", \"44\", \"5\", \"51\", \"53\" (and 8 more)]; sex: [\"F\", \"M\"]; medianus_stimulation: [\"L\", \"LR\", \"R\"]; tibialis_stimulation: [\"L\", \"LR\", \"R\"]; erb_sep: [\"N\"]; subcortical_sep: [\"N\"]; eeg_montage: [\"extended 10-20\"]",
        "tasks": [],
        "events": [],
        "extra_docs": "=== code/README_code.md ===\n# Code for SEP rate\nThis code provides walkthroughs on:\n- reading BIDS dataset ('Main_Read_BIDS_Dataset') \n- segmenting ongoing EEG data into SEP sweeps using the stimulus artefact\n- calculating the signal-to-noise-ratio (SNR) with the +/-averaging approach to estimate the noise level\n\n## This code requires the following Matlab toolboxes:\n- FieldTrip (version > 2019) to read .edf data and process the SEP data\n- BIDS-Matlab-Master to read the layout of the BIDS data and extract metadata\n\nPlease download the toolboxes:\nhttps://www.fieldtriptoolbox.org/\nhttps://github.com/bids-standard/bids-matlab\n\n\n## Subfunctions\n- define_events_thresh: It detects the stimulation artefacts with a peak detection approach\n- define_events: It is used to define data in sweeps after the stimulation artifact is detected (alternatively, the folder derivatives provides the segmented SEP sweeps)\n- reject_StimArtifacts: Rejects sweeps that exceed an artefact rejection threshold (default 10 uV)\n- eegfilt: Filters the data with a high/low or band pass filter\n- find_N20_latency: Detects the N20 latency \n- calculateSNR_plus_minus_avg: Calculates the SNR for different number of permutations at a given recording duration. The N20 amplitude is defined as the maximum deflection in a time window around N20 latency. \nThe noise amplitude is estimated as the averaged difference of even-numbered trials and odd-numbered trials (+/-averaging)\n\n## \n\n# Support\nIf you have any inquiries or questions, contact:\n* Vasileios Dimakopoulos (vasileios.dimakopoulos@usz.ch)\n* Johannes Sarnthein (johannes.sarnthein@usz.ch)\n\n=== code/README_code.md ===\n# Code for SEP rate\nThis code provides walkthroughs on:\n- reading BIDS dataset ('Main_Read_BIDS_Dataset') \n- segmenting ongoing EEG data into SEP sweeps using the stimulus artefact\n- calculating the signal-to-noise-ratio (SNR) with the +/-averaging approach to estimate the noise level\n\n## This code requires the following Matlab toolboxes:\n- FieldTrip (version > 2019) to read .edf data and process the SEP data\n- BIDS-Matlab-Master to read the layout of the BIDS data and extract metadata\n\nPlease download the toolboxes:\nhttps://www.fieldtriptoolbox.org/\nhttps://github.com/bids-standard/bids-matlab\n\n\n## Subfunctions\n- define_events_thresh: It detects the stimulation artefacts with a peak detection approach\n- define_events: It is used to define data in sweeps after the stimulation artifact is detected (alternatively, the folder derivatives provides the segmented SEP sweeps)\n- reject_StimArtifacts: Rejects sweeps that exceed an artefact rejection threshold (default 10 uV)\n- eegfilt: Filters the data with a high/low or band pass filter\n- find_N20_latency: Detects the N20 latency \n- calculateSNR_plus_minus_avg: Calculates the SNR for different number of permutations at a given recording duration. The N20 amplitude is defined as the maximum deflection in a time window around N20 latency. \nThe noise amplitude is estimated as the averaged difference of even-numbered trials and odd-numbered trials (+/-averaging)\n\n## \n\n# Support\nIf you have any inquiries or questions, contact:\n* Vasileios Dimakopoulos (vasileios.dimakopoulos@usz.ch)\n* Johannes Sarnthein (johannes.sarnthein@usz.ch)",
        "json_metadata_summary": "=== sub-01/ses-01/eeg/sub-01_ses-01_task-sepRate_run-01_eeg.json ===\nTaskName: sepRate\nSamplingFrequency: 20000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Inomed Medizintechnik GmbH\nManufacturersModelName: Inomed ISIS System\nTaskDescription: Tibial left stimulation at 2.70 Hz\nInstitutionName: Department of Neurosurgery, University Hospital Zurich\nInstitutionAddress: Frauenklinikstrasse 10, 8091 Zurich\nEEGChannelCount: 4\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 134.30005\nRecordingType: continuous\nSubjectArtefactDescription: \nSoftwareVersions: n/a\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-sepRate_run-02_eeg.json ===\nTaskName: sepRate\nSamplingFrequency: 20000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Inomed Medizintechnik GmbH\nManufacturersModelName: Inomed ISIS System\nTaskDescription: Tibial left stimulation at 4.70 Hz\nInstitutionName: Department of Neurosurgery, University Hospital Zurich\nInstitutionAddress: Frauenklinikstrasse 10, 8091 Zurich\nEEGChannelCount: 4\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 80.10005\nRecordingType: continuous\nSubjectArtefactDescription: \nSoftwareVersions: n/a\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-sepRate_run-03_eeg.json ===\nTaskName: sepRate\nSamplingFrequency: 20000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Inomed Medizintechnik GmbH\nManufacturersModelName: Inomed ISIS System\nTaskDescription: Tibial left stimulation at 8.70 Hz\nInstitutionName: Department of Neurosurgery, University Hospital Zurich\nInstitutionAddress: Frauenklinikstrasse 10, 8091 Zurich\nEEGChannelCount: 4\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 156.30005\nRecordingType: continuous\nSubjectArtefactDescription: \nSoftwareVersions: n/a\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-sepRate_run-04_eeg.json ===\nTaskName: sepRate\nSamplingFrequency: 20000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Inomed Medizintechnik GmbH\nManufacturersModelName: Inomed ISIS System\nTaskDescription: Tibial left stimulation at 12.70 Hz\nInstitutionName: Department of Neurosurgery, University Hospital Zurich\nInstitutionAddress: Frauenklinikstrasse 10, 8091 Zurich\nEEGChannelCount: 4\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 109.40005\nRecordingType: continuous\nSubjectArtefactDescription: \nSoftwareVersions: n/a\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-sepRate_run-05_eeg.json ===\nTaskName: sepRate\nSamplingFrequency: 20000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Inomed Medizintechnik GmbH\nManufacturersModelName: Inomed ISIS System\nTaskDescription: Tibial left stimulation at 16.70 Hz\nInstitutionName: Department of Neurosurgery, University Hospital Zurich\nInstitutionAddress: Frauenklinikstrasse 10, 8091 Zurich\nEEGChannelCount: 4\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 146.00005\nRecordingType: continuous\nSubjectArtefactDescription: \nSoftwareVersions: n/a\n\n=== sub-01/ses-02/eeg/sub-01_ses-02_task-sepRate_run-01_eeg.json ===\nTaskName: sepRate\nSamplingFrequency: 20000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Inomed Medizintechnik GmbH\nManufacturersModelName: Inomed ISIS System\nTaskDescription: Tibial right stimulation at 2.70 Hz\nInstitutionName: Department of Neurosurgery, University Hospital Zurich\nInstitutionAddress: Frauenklinikstrasse 10, 8091 Zurich\nEEGChannelCount: 4\nEOGChannelCount: 0\nECGChannelCou...",
        "openneuro_name": "Intraoperative EEG dataset during medianus-tibialis stimulation with 8 different rates",
        "openneuro_doi": "doi:10.18112/openneuro.ds004381.v1.0.2",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 18
      }
    },
    {
      "dataset_id": "DS004752",
      "pathology": "Epilepsy",
      "modality": "Auditory",
      "type": "Memory",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004752.html",
      "openneuro_id": "ds004752",
      "openneuro_url": "https://openneuro.org/datasets/ds004752",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004752",
      "eegdash_subjects": 15,
      "metadata": {
        "title": "Dataset of intracranial EEG, scalp EEG and beamforming sources from epilepsy patients performing a verbal working memory task",
        "dataset_description": "Name: Dataset of intracranial EEG, scalp EEG and beamforming sources from epilepsy patients performing a verbal working memory task\nAuthors: Vasileios Dimakopoulos, Lennart Stieglitz, Lukas Imbach, Johannes Sarnthein\nAcknowledgment: Please cite this paper: https://doi.org/10.7554/eLife.78677\nReferences: Vasileios Dimakopoulos, Pierre Mégevand, Lennart H Stieglitz, Lukas Imbach, Johannes Sarnthein (2022) Information flows from hippocampus to auditory cortex during replay of verbal working memory items eLife 11:e78677. https://doi.org/10.7554/eLife.78677\nDOI: doi:10.18112/openneuro.ds004752.v1.0.1",
        "readme": "### Dataset of intracranial EEG, scalp EEG and beamforming sources from human epilepsy patients performing a verbal working memory task\n\n#### Description\nWe present an electrophysiological dataset recorded from fifteen subjects during a verbal working memory task. Subjects were epilepsy patients undergoing intracranial monitoring for localization of epileptic seizures. Subjects performed a modified Sternberg task in which the encoding of memory items, maintenance, and recall were temporally separated. The dataset includes simultaneously recorded scalp EEG with the 10-20 system, intracranial EEG (iEEG) recorded with depth electrodes, waveforms, and the MNI coordinates and anatomical labels of all intracranial electrodes. The dataset includes also reconstructed virtual sensor data that were created by performing LCMV beamforming on the EEG at specific brain regions including, temporal superior lobe, lateral prefrontal cortex, occipital cortex, posterior parietal cortex, and Broca.  Subject characteristics and information on sessions (set size, match/mismatch, correct/incorrect, response, response time for each trial) are also provided. This dataset enables the investigation of working memory by providing simultaneous scalp EEG and iEEG recordings, which can be used for connectivity analysis, alongside reconstructed beamforming EEG sources that can enable further cognitive analysis such as replay of memory items.\n\n### Repository structure\n\n### Main directory (verbal WM)\n\nContains metadata files in the BIDS standard about the participants and the study. Folders are explained below.\n\n### Subfolders\n\n-   verbalWM/sub-/: Contains folders for each subject, named sub- and session information.\n-   verbalWM/sub-/ses-/ieeg/: Contains the raw iEEG data in .edf format for each subject. Each subject performed more than 1 working memory session (ses-0x) each of which includes ~50 trials.  Each *ieeg.edf file contains continuous iEEG data during the working memory task. Details about the channels are given in the corresponding .tsv file. We also provide the information on the trial start and end in the events.tsv files by specifying the start and end sample of each trial.\n-   verbalWM/sub-/ses-/eeg/: Contains the raw EEG data in .edf format for each subject. Each subject performed more than 1 working memory session (ses-0x) each of which includes ~50 trials.  Each *eeg.edf file contains continuous EEG data during the working memory task. Details about the channels are given in the corresponding .tsv file. We also provide the information on the trial start and end in the events.tsv files by specifying the start and end sample of each trial.\n- verbalWM/derivatives/sub-/: Contains the LCMV beamforming sources during encoding and maintenance. The beamforming sources are in the form of virtual EEG sensors each of which corresponds to a specific brain region. The naming convention used for the virtual sensors is the following: DLPFC; dorsolateral pre-frontal cortex, OFC; orbitofrontal cortex, PPC; posterior parietal cortex, AC; auditory cortex, V1; primary visual cortex\n\n### BIDS Conversion\n\nbids-starter-kid and custom Matlab scripts were used to convert the dataset into BIDS format.\n\n### References\n[1] Dimakopoulos V, Megevand P, Stieglitz LH, Imbach L, Sarnthein J. Information flows from hippocampus to auditory cortex during replay of verbal working memory items. Elife 2022;11. 10.7554/eLife.78677\n\n[2] Boran E, Fedele T, Klaver P, Hilfiker P, Stieglitz L, Grunwald T, et al. Persistent hippocampal neural firing and hippocampal-cortical coupling predict verbal working memory load. Science Advances 2019;5(3):eaav3687. 10.1126/sciadv.aav3687\n\n[3] Boran E, Fedele T, Steiner A, Hilfiker P, Stieglitz L, Grunwald T, et al. Dataset of human medial temporal lobe neurons, scalp and intracranial EEG during a verbal working memory task. Scientific Data 2020;7(1):30. 10.1038/s41597-020-0364-3",
        "participants_overview": "sciAdv_identifier: [\"  1\", \"  2\", \"  3\", \"  4\", \"  5\", \"  6\", \"  7\", \"  8\", \"  9\"]; age: [\"18\", \"19\", \"20\", \"24\", \"28\", \"29\", \"30\", \"31\", \"39\", \"46\" (and 3 more)]; sex: [\"f\", \"m\"]; pathology: [\"brain contusion\", \"dysembryoplastic neuroepithelial tumor\", \"focal cortical dysplasia\", \"focal cortical dysplasia type II\", \"gliosis\", \"hippocampal sclerosis\", \"non-lesional\", \"unclear etiology\", \"xanthoastrocytoma WHO II\"]",
        "tasks": [],
        "events": [],
        "json_metadata_summary": "=== sub-01/ses-01/eeg/sub-01_ses-01_task-verbalWM_run-01_eeg.json ===\nTaskName: verbalWM\nInstitutionName:  Schweizerische Epilepsie-Klinik\nInstitutionAddress: Bleulerstrasse 60, 8008 Zurich\nManufacturer: Neuralynx Inc.\nManufacturersModelName: Neuralynx ATLAS\nTaskDescription: In the task, sets of consonants are presented and have to be memorized. The set size (4, 6, or 8 letters) determines working memory workload. In each trial, presentation of a letter string (encodin...\nEEGReference: electrode near the vertex\nSamplingFrequency: 200\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nCapManufacturer: n/a\nCapManufacturersModelName: n/a\nEEGChannelCount: 19\nECGChannelCount: 0\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 8\nRecordingType: epoched\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-verbalWM_run-01_events.json ===\nonset: {Description, Type}\nduration: {Description, Type, Units}\n\n=== sub-01/ses-01/ieeg/sub-01_ses-01_task-verbalWM_run-01_events.json ===\nonset: {Description, Type}\nduration: {Description, Type, Units}\n\n=== sub-01/ses-01/ieeg/sub-01_ses-01_task-verbalWM_run-01_ieeg.json ===\nTaskName: verbalWM\nSamplingFrequency: 2000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Neuralynx Inc.\nManufacturersModelName: Neuralynx ATLAS\nTaskDescription: In the task, sets of consonants are presented and have to be memorized. The set size (4, 6, or 8 letters) determines working memory workload. In each trial, presentation of a letter string (encodin...\nInstitutionName:  Schweizerische Epilepsie-Klinik\nInstitutionAddress: Bleulerstrasse 60, 8008 Zurich\nECOGChannelCount: 0\nSEEGChannelCount: 48\nEEGChannelCount: 0\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 8\nRecordingType: epoched\n\n=== sub-01/ses-02/eeg/sub-01_ses-02_task-verbalWM_run-01_eeg.json ===\nTaskName: verbalWM\nInstitutionName:  Schweizerische Epilepsie-Klinik\nInstitutionAddress: Bleulerstrasse 60, 8008 Zurich\nManufacturer: Neuralynx Inc.\nManufacturersModelName: Neuralynx ATLAS\nTaskDescription: In the task, sets of consonants are presented and have to be memorized. The set size (4, 6, or 8 letters) determines working memory workload. In each trial, presentation of a letter string (encodin...\nEEGReference: electrode near the vertex\nSamplingFrequency: 200\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nCapManufacturer: n/a\nCapManufacturersModelName: n/a\nEEGChannelCount: 19\nECGChannelCount: 0\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 8\nRecordingType: epoched\n\n=== sub-01/ses-02/eeg/sub-01_ses-02_task-verbalWM_run-01_events.json ===\nonset: {Description, Type}\nduration: {Description, Type, Units}\n\n=== sub-01/ses-02/ieeg/sub-01_ses-02_task-verbalWM_run-01_events.json ===\nonset: {Description, Type}\nduration: {Description, Type, Units}\n\n=== sub-01/ses-02/ieeg/sub-01_ses-02_task-verbalWM_run-01_ieeg.json ===\nTaskName: verbalWM\nSamplingFrequency: 2000\nPowerLineFrequency: 50\nSoftwareFilters: n/a\nHardwareFilters: {HighpassFilter, LowpassFilter}\nManufacturer: Neuralynx Inc.\nManufacturersModelName: Neuralynx ATLAS\nTaskDescription: In the task, sets of consonants are presented and have to be memorized. The set size (4, 6, or 8 letters) determines working memory workload. In each trial, presentation of a letter string (encodin...\nInstitutionName:  Schweizerische Epilepsie-Klinik\nInstitutionAddress: Bleulerstrasse 60, 8008 Zurich\nECOGChannelCount: 0\nSEEGChannelCount: 48\nEEGChannelCount: 0\nEOGChannelCount: 0\nECGChannelCount: 0\nEMGChannelCount: 0\nMiscChannelCount: 0\nTriggerChannelCount: 0\nRecordingDuration: 8\nRecordingType: epoched\n\n=== sub-01/ses-03/eeg/sub-01_ses-03_task-verbalWM_run-01_eeg.json ===\nTaskName: verbalWM\nInstitutionName:  Schweizerische Epilepsie-Klinik\nInstitutionAddress: Bleulerstrasse 60, 8008 Zurich\nManufacturer: Neuralynx Inc.\nManufacturersModelNa...",
        "openneuro_name": "Dataset of intracranial EEG, scalp EEG and beamforming sources from epilepsy patients performing a verbal working memory task",
        "openneuro_doi": "doi:10.18112/openneuro.ds004752.v1.0.1",
        "openneuro_modalities": [
          "ieeg",
          "eeg"
        ],
        "paper_abstract": "[Paper 1/1 - DOI: 10.7554/eLife.78677]\nThe maintenance of items in working memory (WM) relies on a widespread network of cortical areas and hippocampus where synchronization between electrophysiological recordings reflects functional coupling. We investigated the direction of information flow between auditory cortex and hippocampus while participants heard and then mentally replayed strings of letters in WM by activating their phonological loop. We recorded local field potentials from the hippocampus, reconstructed beamforming sources of scalp EEG , and – additionally in four participants – recorded from subdural cortical electrodes. When analyzing Granger causality, the information flow was from auditory cortex to hippocampus with a peak in the [4 8] Hz range while participants heard the letters. This flow was subsequently reversed during maintenance while participants maintained the letters in memory. The functional interaction between hippocampus and the cortex and the reversal of information flow provide a physiological basis for the encoding of memory items and their active replay during maintenance.",
        "eegdash_subjects": 15
      }
    },
    {
      "dataset_id": "DS004840",
      "pathology": "Other",
      "modality": "Auditory",
      "type": "ClinicalIntervention",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004840.html",
      "openneuro_id": "ds004840",
      "openneuro_url": "https://openneuro.org/datasets/ds004840",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004840",
      "eegdash_subjects": 9,
      "metadata": {
        "title": "Dataset of electrophysiological signals (EEG, ECG, EMG) during Music therapy with adult burn patients in the Intensive Care Unit.",
        "dataset_description": "Name: Dataset of electrophysiological signals (EEG, ECG, EMG) during Music therapy with adult burn patients in the Intensive Care Unit.\nAuthors: Jose Cordoba-Silva, Rafael Maya, Mario Valderrama, Luis Felipe Giraldo, William Betancourt-Zapata (and 4 more)\nDOI: doi:10.18112/openneuro.ds004840.v1.0.1",
        "readme": "# Dataset of  electrophysiological signals (EEG, ECG, EMG) during Music therapy with adult burn patients in the Intensive Care Unit - README\n\n## Table of Contents\n\n- [1. Experimental Design](#1-experimental-design)\n  - [1.1 Study Overview](#11-study-overview)\n  - [1.2 Electrophysiological Measurements](#12-electrophysiological-measurements)\n- [2. Pain Perception and Anxiety-Depression Levels](#2-pain-perception-and-anxiety-depression-levels)\n- [3. Code GIT repository](#3-code-GIT-repository)\n\n## 1. Experimental Design\n\n### 1.1 Study Overview\n\nThis dataset forms part of an ongoing single-site Randomized Clinical Trial (RCT) involving adult burn patients admitted to the Intensive Care Unit (ICU). The key details of the study include:\n\n- **Participants**: The study encompasses 82 adult burn patients admitted to the ICU.\n- **Randomization**: Participants were randomly assigned to either an intervention group or a control group in a 1:1 ratio. The intervention group received standard care in addition to a maximum of six Music therapy sessions provided by a certified music therapist over a 2-week period.\n- **Electrophysiological Measures**: Electrophysiological measures were taken from a subset of 9 participants in the intervention group (11%).\n- **Ethics and Registration**: The study was approved by the ethics committee of the Fundación Santa Fe de Bogotá (FSFB) with approval IDs CCEI-11234-2019 and CCEI-11971-2020. It is registered on Clinicaltrials.gov under the identifier NCT04571255.\n- **Informed Consent**: All participants provided informed consent to participate in the study.\n\n### 1.2 Electrophysiological Measurements\n\n- **Participants**: The electrophysiological measurements were conducted with nine adult burn patients hospitalized in the ICU of the University Hospital Fundación Santa Fe de Bogotá (FSFB).\n- **Inclusion Criteria**: Inclusion criteria involved individuals of legal adult age with an expected hospitalization period of more than 7 days. Patients with known psychiatric disorders, cognitive disabilities, sedation, or mechanical ventilation were excluded. Patients with burns in regions above the neck were also excluded.\n- **Measurement Sessions**: Electrophysiological measurements were performed with each patient during two Music-Assisted Relaxation (MAR) sessions on two different days.\n- **Recording Phases**: Each recording session included three phases:\n  - Pre-Intervention (PRE): The resting state was measured as a baseline with the patient's eyes closed or fixed at a point.\n  - MAR MTI: The specialist performed the MAR MTI.\n  - Post-Intervention (POST): Measurements were taken during the patient's reincorporation after MAR.\n- **Equipment**: Recordings were made with the Micromed LTM64 equipment with a sampling frequency of at least 256Hz. The Micromed LTM64 is of clinical quality and has approval from the Colombian National Institute for Drug and Food Safety (approval ID: 20090486-2015).\n- **Electrode Setup**:\n  - EEG: The electrode montage followed the international System 10-20. Due to time limitations, the number of electrodes was reduced to eight: FP1, FP2, T3, T4, C3, C4, O1, and O2. The reference electrode was set to Cz, and the ground electrode was placed on the mastoids.\n  - ECG: ECG was acquired by a bipolar assembly of lead II with two electrodes located bilaterally in the upper part of the thorax or both arms, depending on each patient's possibilities or limitations.\n  - EMG: For EMG, a bipolar electrode configuration was positioned on the left eyebrow to assess the motor activity of the corrugator supercilii muscle. The electrodes were placed with a 20 mm distance between them, following the natural alignment of the muscle fibers.\n\n## 2. Pain Perception and Anxiety-Depression Levels\n\n- **Measures**: To correlate pain, anxiety, and depression levels with electrophysiological signals, two complementary measures were obtained.\n- **Pain Assessment**: A Visual Analog Scale (VAS) was administered before...",
        "participants_overview": "sex: [\"F\", \"M\"]; age: [\"18\", \"19\", \"20\", \"28\", \"29\", \"36\", \"58\", \"65\"]; burn_type: [\"Electric\", \"Termic\"]; burn_severity: [\"1\", \"2\"]; medication: [\"-\", \"Acetaminophen\", \"Hydrocodone\", \"Hydromorphone\", \"Hydromorphone \", \"Oxycodone\"]; VAS_PRE_session1: [\"0\", \"1\", \"2\", \"3\"]; VAS_POST_session1: [\"0\", \"1\", \"2\"]; VAS_PRE_session2: [\"-\", \"0\", \"4\", \"7\", \"8\"]; VAS_POST_session2: [\"-\", \"0\", \"1\", \"4\", \"6\", \"7\"]; A-HADS_baseline: [\"0\", \"11\", \"2\", \"4\", \"7\", \"9\"]; D-HADS_baseline: [\"0\", \"2\", \"3\", \"4\", \"6\", \"7\"]; T-HADS_baseline: [\"0\", \"11\", \"12\", \"14\", \"16\", \"17\", \"2\", \"5\", \"6\"]; A-HADS_last: [\"-\", \"1\", \"2\", \"4\", \"6\", \"8\", \"9\"]; D-HADS_last: [\"-\", \"0\", \"1\", \"2\", \"9\"]; T-HADS_last: [\"-\", \"1\", \"10\", \"18\", \"2\", \"3\", \"6\", \"7\"]",
        "tasks": [],
        "events": [],
        "json_metadata_summary": "=== sub-01/ses-01/eeg/sub-01_ses-01_task-musicTherapy_eeg.json ===\nInstitutionAddress: University of lo Andes Cra 1 Nº 18A - 12, Bogotá - Colombia, 111711\nInstitutionName: University of lo Andes\nInstitutionalDepartmentName: Department of Biomedical Engineering\nPowerLineFrequency: 60\nManufacturersModelName: Micromed LTM64, Colombian National Institute for Drug and Food Safety (20090486-2015)\nTaskName: task-musicTherapy\nTaskDescription: Music therapy intervention(MTI) consisted of Music - Assisted Relaxation(MAR), a music therapy technique aimed at enhancing relaxation and well - being of patients\nEEGReference: FCz\nEEGChannelCount: 8\nECGChannelCount: 0\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nRecordingType: continuous\nRecordingDuration: 1346\nSamplingFrequency: 1024\nSoftwa...\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-postMusicTherapy_eeg.json ===\nInstitutionAddress: University of lo Andes Cra 1 Nº 18A - 12, Bogotá - Colombia, 111711\nInstitutionName: University of lo Andes\nInstitutionalDepartmentName: Department of Biomedical Engineering\nPowerLineFrequency: 60\nManufacturersModelName: Micromed LTM64, Colombian National Institute for Drug and Food Safety (20090486-2015)\nTaskName: task-postMusicTherapy\nTaskDescription: Post-intervention (POST) period was measured during the patient's reincorporation after MAR\nEEGReference: FCz\nEEGChannelCount: 8\nECGChannelCount: 0\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nRecordingType: continuous\nRecordingDuration: 257\nSamplingFrequency: 1024\nSoftwareFilters: n/a\n\n=== sub-01/ses-01/eeg/sub-01_ses-01_task-preMusicTherapy_eeg.json ===\nInstitutionAddress: University of lo Andes Cra 1 Nº 18A - 12, Bogotá - Colombia, 111711\nInstitutionName: University of lo Andes\nInstitutionalDepartmentName: Department of Biomedical Engineering\nPowerLineFrequency: 60\nManufacturersModelName: Micromed LTM64, Colombian National Institute for Drug and Food Safety (20090486-2015)\nTaskName: task-preMusicTherapy\nTaskDescription: Pre-intervention period, the resting state was measured as a baseline with the patient's eyes closed or fixed at a point\nEEGReference: FCz\nEEGChannelCount: 8\nECGChannelCount: 0\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nRecordingType: continuous\nRecordingDuration: 447\nSamplingFrequency: 1024\nSoftwareFilters: n/a\n\n=== sub-01/ses-02/eeg/sub-01_ses-02_task-musicTherapy_eeg.json ===\nInstitutionAddress: University of lo Andes Cra 1 Nº 18A - 12, Bogotá - Colombia, 111711\nInstitutionName: University of lo Andes\nInstitutionalDepartmentName: Department of Biomedical Engineering\nPowerLineFrequency: 60\nManufacturersModelName: Micromed LTM64, Colombian National Institute for Drug and Food Safety (20090486-2015)\nTaskName: task-musicTherapy\nTaskDescription: Music therapy intervention(MTI) consisted of Music - Assisted Relaxation(MAR), a music therapy technique aimed at enhancing relaxation and well - being of patients\nEEGReference: FCz\nEEGChannelCount: 8\nECGChannelCount: 1\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nRecordingType: continuous\nRecordingDuration: 1449\nSamplingFrequency: 1024\nSoftwa...\n\n=== sub-01/ses-02/eeg/sub-01_ses-02_task-postMusicTherapy_eeg.json ===\nInstitutionAddress: University of lo Andes Cra 1 Nº 18A - 12, Bogotá - Colombia, 111711\nInstitutionName: University of lo Andes\nInstitutionalDepartmentName: Department of Biomedical Engineering\nPowerLineFrequency: 60\nManufacturersModelName: Micromed LTM64, Colombian National Institute for Drug and Food Safety (20090486-2015)\nTaskName: task-postMusicTherapy\nTaskDescription: Post-intervention (POST) period was measured during the patient's reincorporation after MAR\nEEGReference: FCz\nEEGChannelCount: 8\nECGChannelCount: 1\nEMGChannelCount: 0\nEOGChannelCount: 0\nMiscChannelCount: 0\nRecordingType: continuous\nRecordingDuration: 201\nSamplingFrequency: 1024\nSoftwareFilters: n/a\n\n=== sub-01/ses-02/eeg/sub-01_ses-02_task-preMusicTherapy_eeg.json ===\nInstitutionAddress: University of lo Andes Cra 1 Nº ...",
        "openneuro_name": "Dataset of electrophysiological signals (EEG, ECG, EMG) during Music therapy with adult burn patients in the Intensive Care Unit.",
        "openneuro_doi": "doi:10.18112/openneuro.ds004840.v1.0.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 9
      }
    },
    {
      "dataset_id": "DS004796",
      "pathology": "Other",
      "modality": "VisualResting State",
      "type": "MemoryResting-state",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004796.html",
      "openneuro_id": "ds004796",
      "openneuro_url": "https://openneuro.org/datasets/ds004796",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004796",
      "eegdash_subjects": 79,
      "metadata": {
        "title": "A Polish Electroencephalography, Alzheimer’s Risk-genes, Lifestyle and Neuroimaging (PEARL-Neuro) Database",
        "dataset_description": "Name: A Polish Electroencephalography, Alzheimer’s Risk-genes, Lifestyle and Neuroimaging (PEARL-Neuro) Database\nAuthors: Dzianok Patrycja, Kublik Ewa\nAcknowledgment: Dzianok P, Kublik E. PEARL-Neuro Database: EEG, fMRI, health and lifestyle data of middle-aged people at risk of dementia. Sci Data 11, 276 (2024). DOI: https://doi.org/10.1038/s41597-024-03106-5\nReferences: \nDOI: doi:10.18112/openneuro.ds004796.v1.1.0",
        "readme": "## A Polish Electroencephalography, Alzheimer’s Risk-genes, Lifestyle and Neuroimaging (PEARL-Neuro) Database \n\nIMPORTANT NOTE: The dataset contains no errors (BIDS-1). The numerous warnings currently displayed are a result of OpenNeuro updating its validator to BIDS-2. The OpenNeuro team is actively working on refining the validator to display only meaningful warnings (more information on OpenNeuro GitHub page). At this time, as dataset owners, we are unable to take any action to resolve these warnings.\n\n### Data Descriptor:\n* doi.org/10.1038/s41597-024-03106-5 (https://www.nature.com/articles/s41597-024-03106-5)\n\n### Please cite the following reference if you use these data:\n* Dzianok P, Kublik E. PEARL-Neuro Database: EEG, fMRI, health and lifestyle data of middle-aged people at risk of dementia. Sci Data 11, 276 (2024). DOI: https://doi.org/10.1038/s41597-024-03106-5\n\n### Publications related to this dataset, reporting & additional data\n\n* https://github.com/PTDZ/PEARL-Neuro — updates, additional study details, and list of research outputs related to this dataset.\n\nIMPORTANT: Please inform us of any research outputs related to the shared data, including publications, preprints, posters, abstracts, talks, and any commercial usage. This is crucial for ensuring transparency and informing users about the analyses already performed on this dataset. Additionally, such information can foster collaboration.\n\n### Description of the database:\n\nFull cohort: 192 healthy middle-aged (50-63) individuals, balanced female and male ratio. \n\n* Genetic data (N = 192):\n\t* Apolipoprotein E (APOE) \n\t* Phosphatidylinositol binding clathrin assembly protein (PICALM)\n* Basic demographic and health data\n* Psychometric data (memory, intelligence, mood, personality, stress coping strategies)\n\nCohort subgroup: 79 healthy middle-aged (50-63) individuals, balanced female and male ratio.\n\n* Neuroimaging data:\n\t* Functional data — electroencefalography (EEG) and functional magnetic resonance imaging (fMRI):\n\t\t* Resting-state protocol (with two conditions: eyes open and eyes closed) \n\t\t* Cognitive tasks: multi-source interference task (MSIT) and Sternberg’s memory task\n* Blood tests data (blood count, lipid profile, HSV virus)\n\n### Release history:\n* 10/2023: Initial release\n* 02/2024: Public release\n* 06/2025, version: 1.1.0 — marker corrections in .tsv and .vmrk EEG resting-state files\n\nDuring EEG data acquisition, technical issues led to missing starting markers for the eyes-open and/or eyes-closed conditions in the resting-state protocol for some participants. As described in the Data Note, the S1 marker indicates the end of the instruction phase—when the participant presses \"Enter\" to begin a condition (either eyes-open or eyes-closed). Consequently, the first S1 marker coincides with the S2 marker (start of the eyes-open condition), and the second S1 marker aligns with the S4 marker (start of the eyes-closed condition).\n\nTo ensure consistency with Table 5 in the released Data Note, the missing markers were added to the relevant files (.tsv and .vmrk) for the following participants: 08, 09, 11, 12, 14, 15, 21, 22, 25, 35, 42, 54, 62, 64, 65, 67, 70, 71, 73, 75, and 79.\n\nFor participants 19 and 30, the S11 marker (indicating the end of the task and accompanying sound effect) was not saved, resulting in a slightly shorter eyes-closed recording duration (by approximately 30–60 seconds).\n\nFor participant 34, the S11 marker was also not recorded because he/she forgot to press \"Enter\" to mark the start of the eyes-closed condition, pressing it only after the condition had ended. However, he/she followed the instructions and kept his/her eyes closed during the condition. Therefore, the relevant markers (S1/S4) were manually adjusted to reflect the correct start time.",
        "participants_overview": "second_phase: [\"0\", \"1\"]; session_order: [\"0\", \"1\"]; APOE_rs429358: [\"C/C\", \"T/?\", \"T/C\", \"T/T\"]; APOE_rs7412: [\"C/C\", \"C/T\", \"C/T \", \"T/C\", \"T/T\"]; APOE_haplotype: [\"e2/e2\", \"e2/e4\", \"e3/e2\", \"e3/e2 \", \"e3/e3\", \"e3/e4\", \"e4/e4\"]; PICALM_rs3851179: [\"A/A\", \"G/A\", \"G/A \", \"G/G\"]; age: [\"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\" (and 4 more)]; sex: [\"0\", \"1\"]; education: [\"1\", \"2\", \"3\"]; learning_deficits: [\"0\", \"1\", \"2\", \"4\", \"[0. 1 ]\", \"[1. 2]\"]; allergies: [\"0\", \"1\"]; drugs: [\"0\", \"1\"]; ibuprofen_intake: [\"0\", \"1\", \"2\", \"3\", \"4\"]; thyroid_diseases: [\"0\", \"1\", \"2\", \"3\"]; hypertension: [\"0\", \"1\"]; diabetes: [\"0\", \"1\"]; other_diseases: [\"0\", \"1\"]; smoking_status: [\"0\", \"1\", \"2\"]; coffee_status: [\"0\", \"1\", \"2\", \"3\"]; dementia_history_parents: [\"0\", \"1\", \"2\"]; MINI-COPE_1: [\"0.5\", \"1\", \"1.5\", \"2\", \"2.5\", \"3\"]; MINI-COPE_2: [\"0.5\", \"1\", \"1.5\", \"2\", \"2.5\", \"3\"]; MINI-COPE_3: [\"0\", \"0.5\", \"1\", \"1.5\", \"2\", \"2.5\", \"3\"]; MINI-COPE_4: [\"0\", \"0.5\", \"1\", \"1.5\", \"2\", \"2.5\", \"3\"]; ...",
        "tasks": [
          "msit",
          "msit",
          "rest",
          "rest",
          "sternberg",
          "sternberg"
        ],
        "events": [
          "S  1",
          "S  2",
          "S  3",
          "S  4",
          "S  5",
          "S 10",
          "S 11",
          "S 12",
          "response",
          "start_pulse",
          "stimulus"
        ],
        "task_details": "Task 'msit':\nTaskDescription: MSIT is a task design to study cognitive control and conflict processing. Standard version was firstly described by Bush et al. in 2006. Three digits are displayed in the center of the screen, including two digits that are always identical and one deviant. Participants are instructed to indicate the deviant digit in each set. The task was fully described in the corresponding research paper.\n\nTask 'rest':\nTaskDescription: The resting state protocol (rest) is widely used to monitor spontaneous brain activity. During the EEG session, subjects were instructed to remain still and quiet, firstly with they eyes open (for 4 minutes) and then with the eyes closed (for 6 minutes). In the fMRI recording only the resting state eyes closed condition was introduced. The task was fully described in the corresponding research paper.\n\nTask 'sternberg':\nTaskName: sternberg\nTaskDescription: The Sternberg Memory Task is a widely used psychological paradigm designed to investigate short-term or working memory processes. It was developed by Saul Sternberg in 1966 and has been used extensively in psychological and neuroimaging research. The task was fully described in the corresponding research paper.",
        "json_metadata_summary": "=== genetic_info.json ===\nGeneticLevel: Genetic\nAnalyticalApproach: SNP Genotypes (PCR)\nSampleOrigin: other biospecimen\n\n=== task-msit_events.json ===\nonset: {Description, Units}\nduration: {Description, Units}\nevent_type: {Description, Levels}\ntrial_type: {Description, Levels}\n\n=== task-rest_events.json ===\nonset: {Description, Units}\nduration: {Description, Units}\nevent_type: {Description, Levels}\ntrial_type: {Description}\n\n=== task-sternberg_events.json ===\nonset: {Description, Units}\nduration: {Description, Units}\nevent_type: {Description, Levels}\ntrial_type: {Description, Levels}\n\n=== sub-01/func/sub-01_task-msit_dir-AP_bold.json ===\nTaskName: msit\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j-\n\n=== sub-01/func/sub-01_task-msit_dir-PA_bold.json ===\nTaskName: msit\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j\n\n=== sub-01/func/sub-01_task-rest_dir-AP_bold.json ===\nTaskName: rest\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j-\n\n=== sub-01/func/sub-01_task-rest_dir-PA_bold.json ===\nTaskName: rest\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j\n\n=== sub-01/func/sub-01_task-sternberg_dir-AP_bold.json ===\nTaskName: sternberg\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j-\n\n=== sub-01/func/sub-01_task-sternberg_dir-PA_bold.json ===\nTaskName: sternberg\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j\n\n=== sub-02/func/sub-02_task-msit_dir-AP_bold.json ===\nTaskName: msit\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEncodingDirection: j-\n\n=== sub-02/func/sub-02_task-msit_dir-PA_bold.json ===\nTaskName: msit\nMagneticFieldStrength: 3\nManufacturer: SIEMENS\nManufacturersModelName: Siemens 3T Magnetom Prisma Fit\nDeviceSerialNumber: 167033\nSoftwareVersions: syngo MR E11\nModality: MR\nRepetitionTime: 0.8\nEchoTime: 0.038\nEchoTrainLength: 108\nScanningSequence: EP\nSequenceVariant: SK\nScanOptions: FS\nSequenceName: *epfid2d1_108\nFlipAngle: 52\nPhaseEnc...",
        "openneuro_name": "A Polish Electroencephalography, Alzheimer’s Risk-genes, Lifestyle and Neuroimaging (PEARL-Neuro) Database",
        "openneuro_doi": "doi:10.18112/openneuro.ds004796.v1.1.0",
        "openneuro_modalities": [
          "mri",
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 79
      }
    },
    {
      "dataset_id": "DS005048",
      "pathology": "Dementia",
      "modality": "Auditory",
      "type": "Attention",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS005048.html",
      "openneuro_id": "ds005048",
      "openneuro_url": "https://openneuro.org/datasets/ds005048",
      "github_url": "https://github.com/OpenNeuroDatasets/ds005048",
      "eegdash_subjects": 35,
      "metadata": {
        "title": "40Hz Auditory Entrainment",
        "dataset_description": "Name: 40Hz Auditory Entrainment\nAuthors: Mojtaba Lahijanian, Hamid Aghajan, Zahra Vahabi\nAcknowledgment: Please cite the following article as well as dataset DOI:\nLahijanian, M., Aghajan, H. & Vahabi, Z. Auditory gamma-band entrainment enhances default mode network connectivity in dementia patients. S...\nReferences: https://doi.org/10.1038/s41598-024-63727-z; https://doi.org/10.1101/2021.09.30.462389\nDOI: doi:10.18112/openneuro.ds005048.v1.0.1",
        "readme": "Introduction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \nThis experiment was designed to entrain the brain oscillations through synthetic auditory stimulation conducted on a group of elderly suffering from dementia. Recently, gamma entrainment has been proposed and shown effective in improving several symptoms of Alzheimer's Diseases (AD). The aim of this study is to investigate the effect of entrainment on brain oscillations using EEG signal recording during the auditory brain stimulation. This study was approved by the Review Board of Tehran University of Medical Sciences (Approval ID: IR.TUMS.MEDICINE.REC.1398.524). All methods were performed in accordance with the relevant guidelines and regulations, and all participants provided informed consent before participating and were free to withdraw at any time. To accommodate participants who preferred a shorter duration of data gathering, we designed both short and long sessions for entrainment. This approach aimed to minimize inconvenience for the participants who were less inclined to engage in lengthy procedures.                                                                                                                                                                                                                                                                                     \nEntrainment session and auditory stimulation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \nEach session involved the presentation of a multi-trial auditory stimulus while simultaneou...",
        "participants_overview": "Gender: [\"Female\", \"Male\"]; Age: [\"54\", \"57\", \"59\", \"60\", \"63\", \"64\", \"65\", \"67\", \"68\", \"69\" (and 10 more)]; Group: [\"-\", \"MCI\", \"Mild AD\", \"Moderate AD\", \"Normal\"]",
        "tasks": [
          "40HzAuditoryEntrainment"
        ],
        "events": [
          "Rest",
          "Stimulus"
        ],
        "json_metadata_summary": "=== task-40HzAuditoryEntrainment_events.json ===\nduration: {LongName, Description, Units}\ntrial_type: {LongName, Description}\nresponse_time: {LongName, Description, Units}\nonset: {LongName, Description, Units}\n\n=== sub-01/eeg/sub-01_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-02/eeg/sub-02_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-03/eeg/sub-03_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-04/eeg/sub-04_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250\n\n=== sub-05/eeg/sub-05_task-40HzAuditoryEntrainment_eeg.json ===\nPowerLineFrequency: 50\nSoftwareFilters: {FilterDescription}\nEEGPlacementScheme: 10-20\nEEGReference: average\nInstitutionAddress: Tehran, Iran\nInstitutionalDepartmentName: Geriatric Medicine\nInstitutionName: Ziaeian Hospital\nTaskName: 40HzAuditoryEntrainment\nRecordingType: continuous\nRecordingDuration: 350\nSamplingFrequency: 250",
        "openneuro_name": "40Hz Auditory Entrainment",
        "openneuro_doi": "doi:10.18112/openneuro.ds005048.v1.0.1",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "[Paper 1/2 - DOI: 10.1038/s41598-024-63727-z]\nAbstractDementia, and in particular Alzheimer’s disease (AD), can be characterized by disrupted functional connectivity in the brain caused by beta-amyloid deposition in neural links. Non-pharmaceutical treatments for dementia have recently explored interventions involving the stimulation of neuronal populations in the gamma band. These interventions aim to restore brain network functionality by synchronizing rhythmic energy through various stimulation modalities. Entrainment, a newly proposed non-invasive sensory stimulation method, has shown promise in improving cognitive functions in dementia patients. This study investigates the effectiveness of entrainment in terms of promoting neural synchrony and spatial connectivity across the cortex. EEG signals were recorded during a 40 Hz auditory entrainment session conducted with a group of elderly participants with dementia. Phase locking value (PLV) between different intraregional and interregional sites was examined as an attribute of network synchronization, and connectivity of local and distant links were compared during the stimulation and rest trials. Our findings demonstrate enhanced neural synchrony between the frontal and parietal regions, which are key components of the brain’s default mode network (DMN). The DMN operation is known to be impacted by dementia’s progression, leading to reduced functional connectivity across the parieto-frontal pathways. Notably, entrainment alone significantly improves synchrony between these DMN components, suggesting its potential for restoring functional connectivity.\n\n---\n\n[Paper 2/2 - DOI: 10.1101/2021.09.30.462389]\nAbstractNon-invasive gamma entrainment has shown promising results in alleviating cognitive symptoms of Alzheimer’s disease in mice and humans. In this study, we examine improvements in the synchronization characteristics of the brain’s oscillations induced by 40Hz auditory stimulation based on electroencephalography data recorded from a group of dementia patients. We observed that when the quality of entrainment surpasses a certain level, several indicators of brain synchronization significantly improve. Specifically, the entrained oscillatory activity maintains temporal phase stability in the frontal, parietal, and occipital regions, and persistent spatial phase coupling between them. In addition, notable theta-gamma phase-amplitude coupling is observed in these areas. Interestingly, a high theta power at rest predicts the quality of entrainment. We identify differentiating attributes of temporal/spatial synchronization and cross-frequency coupling in the data of two groups with entrained and non-entrained responses which point to enhanced network synchronization caused by entrainment and can explain its potential therapeutic effects.",
        "eegdash_subjects": 35
      }
    },
    {
      "dataset_id": "DS004000",
      "pathology": "SchizophreniaPsychosis",
      "modality": "Multisensory",
      "type": "Decision-making",
      "detail_url": "https://eegdash.org/api/dataset/eegdash.dataset.DS004000.html",
      "openneuro_id": "ds004000",
      "openneuro_url": "https://openneuro.org/datasets/ds004000",
      "github_url": "https://github.com/OpenNeuroDatasets/ds004000",
      "eegdash_subjects": 43,
      "metadata": {
        "title": "Fribourg Ultimatum Game in Schizophrenia Study",
        "dataset_description": "Name: Fribourg Ultimatum Game in Schizophrenia Study\nAuthors: Anna Padée, Pascal Missonnier, Anne Prévot, Grégoire Favre, Isabelle Gothuey (and 2 more)\nDOI: doi:10.18112/openneuro.ds004000.v1.0.0",
        "readme": "This is a schizophrenia in ultimatum game task study for Fribourg University. Participants were asked to play the UG in both roles, both as responder and proposer. 128 electrode EEG was recorded during the task. 19 patients with psychosis epoisodes and 24 healths controls were recorded during the task.\n\nThis dataset was recorded at the Fribourg University in Switzerland. The project was approved by the Ethics Committee of the University of Fribourg (reference number: 054/13-CER-FR).\n\nParticipants sat in a shielded room, in a comfortable chair and played the game, while EEG was recorded. \n\nFor each role, participants performed three blocks, consisting of 30 repetitions each.",
        "participants_overview": "group: [\"HC\", \"P\"]",
        "tasks": [],
        "events": [],
        "json_metadata_summary": "=== sub-000/eeg/sub-000_task-proposer_run-1_eeg.json ===\nTaskName: responder\nTaskDescription: The task is playing the Ultimatum Game. The game involves two players and the goal is to split a certain sum of money between the players (here, 10CHF). The first player (proposer) offers part of t...\nSamplingFrequency: 2048\nManufacturer: Biosemi\nManufacturersModelName: ActiveTwo AD-Box ADC-17\nCapManufacturer: Biosemi\nCapManufacturersModelName: CAP M 128 ABCD\nEEGChannelCount: 128\nEOGChannelCount: 4\nECGChannelCount: 0\nEMGChannelCount: 0\nEEGReference: Mastoid\nEEGGround: CMS/DRL loop\nPowerLineFrequency: 50\nEEGPlacementScheme: Biosemi ABCD\nRecordingType: continuous\nSoftwareVersions: ActiView 7.07\nSoftwareFilters: n/a\nHardwareFilters: n/a\n\n=== sub-000/eeg/sub-000_task-responder_run-1_eeg.json ===\nTaskName: responder\nTaskDescription: The task is playing the Ultimatum Game. The game involves two players and the goal is to split a certain sum of money between the players (here, 10CHF). The first player (proposer) offers part of t...\nSamplingFrequency: 2048\nManufacturer: Biosemi\nManufacturersModelName: ActiveTwo AD-Box ADC-17\nCapManufacturer: Biosemi\nCapManufacturersModelName: CAP M 128 ABCD\nEEGChannelCount: 128\nEOGChannelCount: 4\nECGChannelCount: 0\nEMGChannelCount: 0\nEEGReference: Mastoid\nEEGGround: CMS/DRL loop\nPowerLineFrequency: 50\nEEGPlacementScheme: Biosemi ABCD\nRecordingType: continuous\nSoftwareVersions: ActiView 7.07\nSoftwareFilters: n/a\nHardwareFilters: n/a\n\n=== sub-001/eeg/sub-001_task-proposer_run-1_eeg.json ===\nTaskName: responder\nTaskDescription: The task is playing the Ultimatum Game. The game involves two players and the goal is to split a certain sum of money between the players (here, 10CHF). The first player (proposer) offers part of t...\nSamplingFrequency: 2048\nManufacturer: Biosemi\nManufacturersModelName: ActiveTwo AD-Box ADC-17\nCapManufacturer: Biosemi\nCapManufacturersModelName: CAP M 128 ABCD\nEEGChannelCount: 128\nEOGChannelCount: 4\nECGChannelCount: 0\nEMGChannelCount: 0\nEEGReference: Mastoid\nEEGGround: CMS/DRL loop\nPowerLineFrequency: 50\nEEGPlacementScheme: Biosemi ABCD\nRecordingType: continuous\nSoftwareVersions: ActiView 7.07\nSoftwareFilters: n/a\nHardwareFilters: n/a\n\n=== sub-001/eeg/sub-001_task-responder_run-1_eeg.json ===\nTaskName: responder\nTaskDescription: The task is playing the Ultimatum Game. The game involves two players and the goal is to split a certain sum of money between the players (here, 10CHF). The first player (proposer) offers part of t...\nSamplingFrequency: 2048\nManufacturer: Biosemi\nManufacturersModelName: ActiveTwo AD-Box ADC-17\nCapManufacturer: Biosemi\nCapManufacturersModelName: CAP M 128 ABCD\nEEGChannelCount: 128\nEOGChannelCount: 4\nECGChannelCount: 0\nEMGChannelCount: 0\nEEGReference: Mastoid\nEEGGround: CMS/DRL loop\nPowerLineFrequency: 50\nEEGPlacementScheme: Biosemi ABCD\nRecordingType: continuous\nSoftwareVersions: ActiView 7.07\nSoftwareFilters: n/a\nHardwareFilters: n/a\n\n=== sub-002/eeg/sub-002_task-proposer_run-1_eeg.json ===\nTaskName: responder\nTaskDescription: The task is playing the Ultimatum Game. The game involves two players and the goal is to split a certain sum of money between the players (here, 10CHF). The first player (proposer) offers part of t...\nSamplingFrequency: 2048\nManufacturer: Biosemi\nManufacturersModelName: ActiveTwo AD-Box ADC-17\nCapManufacturer: Biosemi\nCapManufacturersModelName: CAP M 128 ABCD\nEEGChannelCount: 128\nEOGChannelCount: 4\nECGChannelCount: 0\nEMGChannelCount: 0\nEEGReference: Mastoid\nEEGGround: CMS/DRL loop\nPowerLineFrequency: 50\nEEGPlacementScheme: Biosemi ABCD\nRecordingType: continuous\nSoftwareVersions: ActiView 7.07\nSoftwareFilters: n/a\nHardwareFilters: n/a\n\n=== sub-002/eeg/sub-002_task-responder_run-1_eeg.json ===\nTaskName: responder\nTaskDescription: The task is playing the Ultimatum Game. The game involves two players and the goal is to split a certain sum of money between the players (here, 10CHF). The first player (proposer) offers part of t...\nSamplingFreque...",
        "openneuro_name": "Fribourg Ultimatum Game in Schizophrenia Study",
        "openneuro_doi": "doi:10.18112/openneuro.ds004000.v1.0.0",
        "openneuro_modalities": [
          "eeg"
        ],
        "paper_abstract": "",
        "eegdash_subjects": 43
      }
    }
  ]
}